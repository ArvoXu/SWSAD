import sys
import os
from datetime import datetime, timedelta
from flask import Flask, jsonify, send_from_directory, request, redirect, render_template, session, flash
from flask_cors import CORS
import schedule
import time
import threading
from dotenv import load_dotenv
from sqlalchemy.orm import Session
from sqlalchemy.exc import OperationalError
from sqlalchemy import or_, and_
import subprocess
import logging
import traceback
from dateutil.parser import parse as parse_date
import pandas as pd
import shutil
import json
import pytz
from openpyxl import load_workbook, Workbook
from datetime import datetime
from werkzeug.security import generate_password_hash, check_password_hash
import smtplib
from email.message import EmailMessage


# --- Custom Imports ---
from database import init_db, get_db, Inventory, Store, Transaction, UpdateLog, Warehouse, User, NotificationSent
from scraper import run_scraper as run_inventory_scraper_function, parse_inventory_from_text, save_to_database, save_to_json
from salesscraper import run_sales_scraper
from warehousescraper import run_warehouse_scraper

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- Pre-startup Configuration ---
# Get the directory where the script is located
# This is crucial for making file paths work correctly in any environment
script_dir = os.path.dirname(os.path.abspath(__file__))

# Load environment variables from .env file located in the same directory
# This needs to happen before any other part of the app uses them
dotenv_path = os.path.join(script_dir, '.env')
if os.path.exists(dotenv_path):
    logging.info(f"Loading environment variables from: {dotenv_path}")
    load_dotenv(dotenv_path=dotenv_path)
else:
    logging.info(f".env file not found at {dotenv_path}. Relying on system-set environment variables.")


# --- Flask App Setup ---
app = Flask(__name__, 
            static_folder=script_dir, 
            static_url_path='',
            template_folder=os.path.join(script_dir, 'templates')) # Point to the templates folder
CORS(app) # å…è¨±æ‰€æœ‰ä¾†æºçš„è·¨åŸŸè«‹æ±‚ï¼Œæ–¹ä¾¿æœ¬åœ°é–‹ç™¼

# --- Secret Key for Session Management ---
# It's crucial this is set and kept secret in production.
# We'll load it from an environment variable.
app.secret_key = os.getenv("FLASK_SECRET_KEY", "dev-secret-key-for-local-testing")

# --- Global State for Scraper ---
# This dictionary will hold the state of our scraper job.
# Using a lock to ensure thread-safe updates.
scraper_state = {
    "status": "idle", # Can be 'idle', 'running', 'success', 'error'
    "last_run_output": ""
}
state_lock = threading.Lock()

# --- Global State for Sales Scraper ---
sales_scraper_state = {
    "status": "idle", # Can be 'idle', 'running', 'success', 'error'
    "last_run_output": ""
}
sales_state_lock = threading.Lock()


# --- Global Variables & Constants ---
# Use the script's directory to build absolute paths
# DB_PATH = os.path.join(script_dir, 'inventory.db') # This line is no longer needed
# SCRAPER_SCRIPT_PATH = os.path.join(script_dir, 'scraper.py') # This line is no longer needed
# PYTHON_EXECUTABLE = sys.executable # This line is no longer needed

# --- Database Initialization ---
# Ensure the database and table exist before the app starts serving requests.
# This is crucial for the first run on a new server deployment.
logging.info(f"Initializing database at: {script_dir}")
init_db() # This command creates the tables in our PostgreSQL or SQLite database if they don't exist.
logging.info("Database initialization complete.")


def run_inventory_scraper_background():
    """
    This function runs the scraper in a background thread and updates the global state.
    It now uses the new database functions.
    It's also thread-safe, checking if another job is already running.
    """
    global scraper_state
    
    with state_lock:
        if scraper_state['status'] == 'running':
            logging.warning(f"[{datetime.now()}] Scraper start requested, but a job is already in progress. Aborting.")
            return
        
        # Update state to 'running'
        scraper_state['status'] = 'running'
        scraper_state['last_run_output'] = ''
        logging.info(f"[{datetime.now()}] Scraper status set to 'running'. Starting job.")

    try:
        # We need to call the actual scraper logic here.
        # Since scraper.py's main execution block is complex,
        # we directly call the necessary functions.
        
        # 1. Execute the web scraper to get raw text
        raw_inventory_text = run_inventory_scraper_function(headless=True)
        
        if raw_inventory_text:
            # 2. Parse the raw text into structured data
            structured_data = parse_inventory_from_text(raw_inventory_text)
            
            # --- Define output paths ---
            output_json_path = os.path.join(script_dir, 'structured_inventory.json')
            
            # 3. Save to JSON and Database
            # Convert datetime objects for JSON serialization
            json_serializable_data = []
            for item in structured_data:
                item_copy = item.copy()
                if 'process_time' in item_copy and hasattr(item_copy['process_time'], 'isoformat'):
                    item_copy['process_time'] = item_copy['process_time'].isoformat()
                json_serializable_data.append(item_copy)
            
            save_to_json(json_serializable_data, output_json_path)
            
            # The data is already parsed with datetime objects, so we can save it directly
            items_saved_count = len(structured_data)
            save_to_database(structured_data)

            # After saving inventory to database, immediately run low-inventory notifications
            # Run notifications in a non-blocking daemon thread to avoid delaying the scraper
            try:
                def _notify_runner():
                    try:
                        res = _notify_low_inventory_internal()
                        logging.info(f"Low-inventory notification run after scraper: {res}")
                    except Exception as e:
                        logging.error(f"Error running notifications in background thread: {e}", exc_info=True)

                t = threading.Thread(target=_notify_runner, daemon=True)
                t.start()
                logging.info("Started background notification thread after scraper run.")
            except Exception as e:
                logging.error(f"Failed to start notification thread: {e}", exc_info=True)

            output = f"Scraper finished successfully. Processed {items_saved_count} items. Notifications run." 
            status = "success"
        else:
            output = "Scraper ran but returned no data."
            status = "error"
            
    except Exception as e:
        output = f"An error occurred in background scraper: {str(e)}"
        status = "error"
        logging.error(output, exc_info=True)
    
    # Update state with the final result
    with state_lock:
        scraper_state['status'] = status
        scraper_state['last_run_output'] = output
        
    # Log the update to the database with a retry mechanism
    log_db_update(scraper_type='inventory', status=status, details=output)


def run_sales_scraper_background():
    """
    Runs the sales scraper in a background thread, processes the downloaded file,
    and updates the database with a retry mechanism.
    """
    global sales_scraper_state
    
    with sales_state_lock:
        if sales_scraper_state['status'] == 'running':
            logging.warning(f"[{datetime.now()}] Sales scraper start requested, but a job is already in progress. Aborting.")
            return
        sales_scraper_state['status'] = 'running'
        sales_scraper_state['last_run_output'] = ''
        logging.info(f"[{datetime.now()}] Sales scraper status set to 'running'. Starting job.")

    downloaded_file_path = None
    try:
        # 1. Run the scraper to download the file
        # We explicitly set headless=True to ensure it runs without a GUI on the server.
        downloaded_file_path = run_sales_scraper(headless=True)
        
        # 2. Process the downloaded Excel file
        if downloaded_file_path:
            df = pd.read_excel(downloaded_file_path)
            df.rename(columns={
                'Shop name': 'shopName',
                'Product': 'product',
                'Trasaction Date': 'date',
                'Total Transaction Amount': 'amount',
                'Pay type': 'payType'
            }, inplace=True)
            transactions_data = df.to_dict('records')
            
            # 3. Add transactions to the DB with retry logic
            max_retries = 3
            retry_delay_seconds = 5
            for attempt in range(max_retries):
                db: Session = next(get_db())
                try:
                    # This block is a simplified version of the logic in add_transactions endpoint
                    db.query(Transaction).delete()
                    
                    all_stores = db.query(Store).all()
                    store_name_map = {}
                    for s in all_stores:
                        name_parts = s.store_key.rsplit('-', 1)
                        name = name_parts[0]
                        if name not in store_name_map:
                            store_name_map[name] = s

                    new_transactions = []
                    for item in transactions_data:
                        shop_name_raw = item.get('shopName')
                        if not shop_name_raw or pd.isna(item.get('date')):
                            continue
                        
                        shop_name = str(shop_name_raw).strip()
                        store = store_name_map.get(shop_name)
                        
                        if not store:
                            new_store_key = f"{shop_name}-provisional_sales"
                            store = db.query(Store).filter(Store.store_key == new_store_key).first()
                            if not store:
                                store = Store(store_key=new_store_key)
                                db.add(store)
                                db.flush()
                            store_name_map[shop_name] = store

                        new_transactions.append(Transaction(
                            store_key=store.store_key,
                            transaction_time=pd.to_datetime(item.get('date')),
                            amount=int(float(item.get('amount', 0))),
                            product_name=str(item.get('product')),
                            payment_type=str(item.get('payType'))
                        ))

                    if new_transactions:
                        db.bulk_save_objects(new_transactions)
                    
                    db.commit()
                    processed_count = len(new_transactions)
                    output = f"Sales scraper finished successfully. Processed {processed_count} transactions."
                    status = "success"
                    logging.info(f"Database operation successful on attempt {attempt + 1}.")
                    db.close()
                    break # Exit retry loop on success
                except OperationalError as e:
                    db.rollback()
                    db.close()
                    logging.error(f"Sales DB error (Attempt {attempt + 1}/{max_retries}): {e}")
                    if attempt + 1 >= max_retries:
                        output = f"Sales scraper failed after {max_retries} attempts: {e}"
                        status = "error"
                        raise
                    logging.info(f"Retrying in {retry_delay_seconds} seconds...")
                    time.sleep(retry_delay_seconds)
                finally:
                    # Ensure db is closed if it's still open
                    if 'db' in locals() and db.is_active:
                         db.close()
        else:
            output = "Sales scraper ran but did not return a file path."
            status = "error"
            
    except Exception as e:
        output = f"An error occurred in background sales scraper: {str(e)}"
        status = "error"
        logging.error(output, exc_info=True)
    finally:
        # 4. Clean up downloaded file and temp directory
        if downloaded_file_path:
            download_dir = os.path.dirname(downloaded_file_path)
            try:
                shutil.rmtree(download_dir)
                logging.info(f"Successfully cleaned up temporary directory: {download_dir}")
            except OSError as e:
                logging.error(f"Error removing directory {download_dir}: {e.strerror}")
                
        with sales_state_lock:
            sales_scraper_state['status'] = status
            sales_scraper_state['last_run_output'] = output
            
        # Log the update to the database with a retry mechanism
        log_db_update(scraper_type='sales', status=status, details=output)


def log_db_update(scraper_type, status, details):
    """Logs an update record to the database with a retry mechanism."""
    max_retries = 3
    retry_delay = 5
    for attempt in range(max_retries):
        db_log: Session = next(get_db())
        try:
            log_entry = UpdateLog(scraper_type=scraper_type, status=status, details=details)
            db_log.add(log_entry)
            db_log.commit()
            logging.info(f"Successfully logged '{status}' for '{scraper_type}' scraper.")
            return
        except OperationalError as e:
            db_log.rollback()
            logging.error(f"Failed to write to update_logs (Attempt {attempt + 1}/{max_retries}): {e}")
            if attempt + 1 >= max_retries:
                logging.error(f"Giving up on logging after {max_retries} attempts.")
            else:
                logging.info(f"Retrying log write in {retry_delay} seconds...")
                time.sleep(retry_delay)
        except Exception as e:
            db_log.rollback()
            logging.error(f"An unexpected error occurred while writing to update_logs: {e}", exc_info=True)
            return # Don't retry on unexpected errors
        finally:
            db_log.close()


# --- Warehouse Scraper Background Function ---
def run_warehouse_scraper_background():
    """
    åœ¨èƒŒæ™¯åŸ·è¡Œå€‰åº«çˆ¬èŸ²ï¼Œè™•ç†ä¸‹è¼‰çš„æª”æ¡ˆä¸¦æ›´æ–°è³‡æ–™åº«ã€‚
    """
    global sales_scraper_state
    
    with sales_state_lock:
        if sales_scraper_state['status'] == 'running':
            logging.warning(f"[{datetime.now()}] Warehouse scraper start requested, but a job is already in progress. Aborting.")
            return
        sales_scraper_state['status'] = 'running'
        sales_scraper_state['last_run_output'] = ''
        logging.info(f"[{datetime.now()}] Warehouse scraper status set to 'running'. Starting job.")

    downloaded_file_path = None
    try:
        # 1. åŸ·è¡Œçˆ¬èŸ²ä¸‹è¼‰æª”æ¡ˆ
        downloaded_file_path = run_warehouse_scraper(headless=True)
        
        # 2. è™•ç†ä¸‹è¼‰çš„ Excel æª”æ¡ˆ
        if downloaded_file_path:
            df = pd.read_excel(downloaded_file_path)
            
            # ç¢ºä¿å¿…è¦çš„æ¬„ä½å­˜åœ¨
            required_columns = ['Warehouse name', 'Product name', 'Remain quantity']
            missing_columns = [col for col in required_columns if col not in df.columns]
            if missing_columns:
                raise ValueError(f"Excel æª”æ¡ˆç¼ºå°‘å¿…è¦æ¬„ä½: {', '.join(missing_columns)}")
            
            # æ›´æ–°è³‡æ–™åº«
            max_retries = 3
            retry_delay_seconds = 5
            
            for attempt in range(max_retries):
                db: Session = next(get_db())
                try:
                    # è¨˜éŒ„ç•¶å‰æ™‚é–“ä½œç‚ºæ›´æ–°æ™‚é–“
                    update_time = datetime.now()
                    
                    # å°‡è³‡æ–™è½‰æ›ç‚ºè³‡æ–™åº«è¨˜éŒ„
                    warehouse_records = []
                    for _, row in df.iterrows():
                        warehouse_records.append(Warehouse(
                            warehouse_name=row['Warehouse name'],
                            product_name=row['Product name'],
                            quantity=int(row['Remain quantity']),
                            updated_at=update_time
                        ))
                    
                    # åˆªé™¤èˆŠçš„å€‰åº«è³‡æ–™
                    db.query(Warehouse).delete()
                    
                    # æ–°å¢æ–°çš„å€‰åº«è³‡æ–™
                    db.bulk_save_objects(warehouse_records)
                    db.commit()
                    
                    output = f"æˆåŠŸæ›´æ–°å€‰åº«è³‡æ–™ã€‚è™•ç†äº† {len(warehouse_records)} ç­†è¨˜éŒ„ã€‚"
                    status = "success"
                    break
                    
                except OperationalError as e:
                    db.rollback()
                    if attempt + 1 >= max_retries:
                        raise
                    logging.error(f"è³‡æ–™åº«æ“ä½œå¤±æ•— (å˜—è©¦ {attempt + 1}/{max_retries}): {e}")
                    time.sleep(retry_delay_seconds)
                finally:
                    db.close()
        else:
            output = "å€‰åº«çˆ¬èŸ²åŸ·è¡Œå®Œæˆä½†æœªè¿”å›æª”æ¡ˆè·¯å¾‘ã€‚"
            status = "error"
            
    except Exception as e:
        output = f"å€‰åº«çˆ¬èŸ²éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
        status = "error"
        logging.error(output, exc_info=True)
    finally:
        # æ¸…ç†ä¸‹è¼‰çš„æª”æ¡ˆå’Œæš«å­˜ç›®éŒ„
        if downloaded_file_path:
            download_dir = os.path.dirname(downloaded_file_path)
            try:
                shutil.rmtree(download_dir)
                logging.info(f"æˆåŠŸæ¸…ç†æš«å­˜ç›®éŒ„: {download_dir}")
            except OSError as e:
                logging.error(f"ç§»é™¤ç›®éŒ„æ™‚ç™¼ç”ŸéŒ¯èª¤ {download_dir}: {e.strerror}")
                
        with sales_state_lock:
            sales_scraper_state['status'] = status
            sales_scraper_state['last_run_output'] = output
            
        # è¨˜éŒ„æ›´æ–°åˆ°è³‡æ–™åº«
        log_db_update(scraper_type='warehouse', status=status, details=output)

# --- API Endpoints ---
@app.route('/run-scraper', methods=['POST'])
def trigger_scraper():
    """
    Triggers the scraper script to run in a background thread.
    Returns immediately so the client doesn't time out.
    """
    with state_lock:
        if scraper_state['status'] == 'running':
            return jsonify({'success': False, 'message': 'Scraper is already running.'}), 409

    logging.info(f"[{datetime.now()}] Received request to run scraper in background.")
    # Run the scraper in a separate thread
    thread = threading.Thread(target=run_inventory_scraper_background)
    thread.start()
    
    return jsonify({'success': True, 'message': 'Scraper job started in the background.'}), 202

@app.route('/upload-inventory-file', methods=['POST'])
def upload_inventory_file():
    """
    æ¥æ”¶æ ¼å¼åŒ–å¥½çš„åº«å­˜æ•¸æ“šæ–‡ä»¶ï¼ˆJSONæ ¼å¼ï¼‰ä¸¦ç›´æ¥ä¿å­˜åˆ°æ•¸æ“šåº«
    é¿å…åœ¨ä¼ºæœå™¨ä¸Šé‹è¡Œçˆ¬èŸ²è…³æœ¬ï¼Œæ¸›å°‘CPUè² è¼‰
    """
    try:
        # æª¢æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ä¸Šå‚³
        if 'file' not in request.files:
            return jsonify({'success': False, 'message': 'æ²’æœ‰é¸æ“‡æ–‡ä»¶'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'success': False, 'message': 'æ²’æœ‰é¸æ“‡æ–‡ä»¶'}), 400
        
        # æª¢æŸ¥æ–‡ä»¶é¡å‹
        if not file.filename.endswith('.json'):
            return jsonify({'success': False, 'message': 'åªæ”¯æŒ JSON æ ¼å¼çš„æ–‡ä»¶'}), 400
        
        # è®€å–æ–‡ä»¶å…§å®¹
        file_content = file.read()
        try:
            inventory_data = json.loads(file_content.decode('utf-8'))
        except json.JSONDecodeError as e:
            return jsonify({'success': False, 'message': f'JSON æ ¼å¼éŒ¯èª¤: {str(e)}'}), 400
        
        # é©—è­‰æ•¸æ“šæ ¼å¼
        if not isinstance(inventory_data, list):
            return jsonify({'success': False, 'message': 'æ•¸æ“šæ ¼å¼éŒ¯èª¤ï¼šæ‡‰è©²æ˜¯åˆ—è¡¨æ ¼å¼'}), 400
        
        # é©—è­‰æ¯å€‹é …ç›®æ˜¯å¦åŒ…å«å¿…è¦å­—æ®µ
        required_fields = ['store', 'machine_id', 'product_name', 'quantity']
        for i, item in enumerate(inventory_data):
            if not isinstance(item, dict):
                return jsonify({'success': False, 'message': f'ç¬¬ {i+1} é …æ•¸æ“šæ ¼å¼éŒ¯èª¤ï¼šæ‡‰è©²æ˜¯å­—å…¸æ ¼å¼'}), 400
            
            missing_fields = [field for field in required_fields if field not in item]
            if missing_fields:
                return jsonify({'success': False, 'message': f'ç¬¬ {i+1} é …ç¼ºå°‘å¿…è¦å­—æ®µ: {", ".join(missing_fields)}'}), 400
            
            # é©—è­‰æ•¸é‡å­—æ®µ
            if not isinstance(item['quantity'], int) or item['quantity'] < 0:
                return jsonify({'success': False, 'message': f'ç¬¬ {i+1} é …æ•¸é‡å­—æ®µéŒ¯èª¤ï¼šæ‡‰è©²æ˜¯æ­£æ•´æ•¸'}), 400
        
        # è™•ç†æ—¥æœŸæ™‚é–“å­—æ®µ
        for item in inventory_data:
            if 'process_time' in item:
                if isinstance(item['process_time'], str):
                    try:
                        item['process_time'] = parse_date(item['process_time'])
                    except Exception as e:
                        return jsonify({'success': False, 'message': f'æ—¥æœŸæ™‚é–“æ ¼å¼éŒ¯èª¤: {str(e)}'}), 400
            else:
                # å¦‚æœæ²’æœ‰ process_timeï¼Œä½¿ç”¨ç•¶å‰æ™‚é–“
                item['process_time'] = datetime.now(pytz.timezone('Asia/Taipei'))
        
        # ä¿å­˜åˆ°æ•¸æ“šåº«
        max_retries = 3
        retry_delay_seconds = 5
        
        for attempt in range(max_retries):
            db: Session = next(get_db())
            try:
                # æ¸…ç©ºç¾æœ‰åº«å­˜æ•¸æ“š
                num_deleted = db.query(Inventory).delete()
                logging.info(f"Cleared {num_deleted} old records from the inventory table.")
                
                # å‰µå»ºæ–°çš„åº«å­˜å°è±¡
                inventory_objects = [Inventory(**item) for item in inventory_data]
                db.bulk_save_objects(inventory_objects)
                
                db.commit()
                items_saved_count = len(inventory_objects)
                logging.info(f"Successfully saved {items_saved_count} new records to the database via file upload.")
                
                # è¨˜éŒ„æ›´æ–°æ—¥èªŒ
                log_db_update(
                    scraper_type='inventory_upload', 
                    status='success', 
                    details=f'File upload successful. Processed {items_saved_count} items from {file.filename}'
                )
                
                db.close()
                return jsonify({
                    'success': True, 
                    'message': f'æˆåŠŸä¸Šå‚³ä¸¦è™•ç† {items_saved_count} é …åº«å­˜æ•¸æ“š',
                    'items_processed': items_saved_count,
                    'filename': file.filename
                })
                
            except OperationalError as e:
                db.rollback()
                db.close()
                logging.error(f"Database error on attempt {attempt + 1}/{max_retries}: {e}")
                if attempt + 1 >= max_retries:
                    log_db_update(
                        scraper_type='inventory_upload', 
                        status='error', 
                        details=f'Database error after {max_retries} attempts: {str(e)}'
                    )
                    return jsonify({'success': False, 'message': f'æ•¸æ“šåº«éŒ¯èª¤ï¼Œå·²é‡è©¦ {max_retries} æ¬¡: {str(e)}'}), 500
                logging.info(f"Retrying in {retry_delay_seconds} seconds...")
                time.sleep(retry_delay_seconds)
                
            except Exception as e:
                db.rollback()
                db.close()
                logging.error(f"Unexpected error during file upload: {e}", exc_info=True)
                log_db_update(
                    scraper_type='inventory_upload', 
                    status='error', 
                    details=f'Unexpected error: {str(e)}'
                )
                return jsonify({'success': False, 'message': f'è™•ç†æ–‡ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}'}), 500
            finally:
                if 'db' in locals() and db.is_active:
                    db.close()
                    
    except Exception as e:
        logging.error(f"Error in file upload endpoint: {e}", exc_info=True)
        return jsonify({'success': False, 'message': f'æ–‡ä»¶ä¸Šå‚³å¤±æ•—: {str(e)}'}), 500

@app.route('/scraper-status', methods=['GET'])
def get_scraper_status():
    """
    Returns the current status of the scraper job.
    """
    with state_lock:
        return jsonify(scraper_state)

@app.route('/run-sales-scraper', methods=['POST'])
def trigger_sales_scraper():
    """
    Triggers the sales scraper to run in a background thread.
    """
    with sales_state_lock:
        if sales_scraper_state['status'] == 'running':
            return jsonify({'success': False, 'message': 'Sales scraper is already running.'}), 409

    logging.info(f"[{datetime.now()}] Received request to run sales scraper in background.")
    thread = threading.Thread(target=run_sales_scraper_background)
    thread.start()
    
    return jsonify({'success': True, 'message': 'Sales scraper job started in the background.'}), 202

@app.route('/sales-scraper-status', methods=['GET'])
def get_sales_scraper_status():
    """
    Returns the current status of the sales scraper job.
    """
    with sales_state_lock:
        return jsonify(sales_scraper_state)

def to_camel_case(snake_str):
    """
    Converts a snake_case string to camelCase.
    Example: 'product_name' -> 'productName'
    """
    components = snake_str.split('_')
    # Capitalize the first letter of each component except the first one
    # and join them together.
    return components[0] + ''.join(x.title() for x in components[1:])

@app.route('/get-data', methods=['GET'])
def get_data():
    """
    Retrieves all inventory and custom store data, merges them,
    and returns them as a single JSON response with camelCase keys.
    """
    db: Session = next(get_db())
    try:
        # If a normal user is logged in (session['user_id']), restrict results to their assigned stores
        user_id = session.get('user_id')
        if user_id:
            user = db.query(User).filter(User.id == int(user_id)).first()
            allowed_store_keys = set()
            if user:
                # user's stores contain store_key strings
                allowed_store_keys = set(s.store_key for s in user.stores)
            # Query inventory with flexible matching: allow matching by
            # 1) exact store + machine (if applicable),
            # 2) Inventory.store equals the prefix part of store_key,
            # 3) Inventory.store LIKE prefix% fallback.
            inventory_items = []
            filters = []
            for sk in allowed_store_keys:
                # if store_key looks like 'store-machine', try exact match first
                if '-' in sk:
                    left, right = sk.rsplit('-', 1)
                    # exact store+machine
                    filters.append(and_(Inventory.store == left, Inventory.machine_id == right))
                    # any machine for that store (case-insensitive)
                    filters.append(Inventory.store.ilike(left))
                    # fallback patterns: startswith and contains (case-insensitive)
                    filters.append(Inventory.store.ilike(f"{left}%"))
                    filters.append(Inventory.store.ilike(f"%{left}%"))
                else:
                    filters.append(Inventory.store.ilike(sk))
                    filters.append(Inventory.store.ilike(f"{sk}%"))
                    filters.append(Inventory.store.ilike(f"%{sk}%"))
            if filters:
                # combine with OR and query
                inventory_items = db.query(Inventory).filter(or_(*filters)).all()
        else:
            inventory_items = db.query(Inventory).all()
        
        # 2. Fetch all custom store data
        stores = db.query(Store).all()
        # Create a dictionary for quick lookups: {'store_key': {address: '...', 'note': '...'}}
        store_info_map = {store.store_key: store.to_dict() for store in stores}

        # 3. Merge the data
        merged_data = []
        for item in inventory_items:
            item_dict = item.to_dict()
            store_key = f"{item.store}-{item.machine_id}"
            
            # Get custom data for this store, if it exists
            custom_store_data = store_info_map.get(store_key, {})
            
            # Merge inventory data with custom store data
            full_item_data = {**item_dict, **custom_store_data}
            
            # 4. Convert all keys to camelCase for the frontend
            camel_case_data = {to_camel_case(key): value for key, value in full_item_data.items()}
            
            # Ensure process_time is in ISO format string
            if 'processTime' in camel_case_data and hasattr(camel_case_data['processTime'], 'isoformat'):
                camel_case_data['processTime'] = camel_case_data['processTime'].isoformat()

            merged_data.append(camel_case_data)
        
        return jsonify({"success": True, "data": merged_data})
        
    except Exception as e:
        return jsonify({"success": False, "message": str(e)}), 500
    finally:
        db.close()


def is_admin():
    """Helper: current session indicates admin if session['logged_in']==True (existing behavior)."""
    return bool(session.get('logged_in'))


@app.route('/api/stores-list', methods=['GET'])
def api_stores_list():
    """Return list of stores for admin forms.

    By default this endpoint returns distinct `Inventory.store` values (so admins
    can assign users based on the inventory naming). If callers want the older
    `Store.store_key` list, pass ?source=stores.
    """
    source = (request.args.get('source') or 'inventory').lower()
    db: Session = next(get_db())
    try:
        if source == 'stores':
            stores = db.query(Store).all()
            result = [s.store_key for s in stores]
        else:
            # default: distinct Inventory.store values
            rows = db.query(Inventory.store).distinct().order_by(Inventory.store).all()
            # rows is list of 1-tuples like [('å°åŒ—å¤©æ–‡é¤¨ å·¦é‚Š',), ...]
            result = [r[0] for r in rows if r and r[0]]
        return jsonify({'success': True, 'stores': result})
    except Exception as e:
        logging.error(f"Error getting stores list: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500
    finally:
        db.close()


@app.route('/api/users', methods=['POST'])
def api_create_user():
    """Admin-only: create a user and assign stores. Request JSON: {username, password, displayName, stores: []} """
    if not is_admin():
        return jsonify({'success': False, 'message': 'æœªæˆæ¬Š'}), 403

    data = request.get_json() or {}
    username = data.get('username')
    password = data.get('password')
    display_name = data.get('displayName') or ''
    stores = data.get('stores') or []

    if not username or not password:
        return jsonify({'success': False, 'message': 'username å’Œ password ç‚ºå¿…å¡«'}), 400

    db: Session = next(get_db())
    try:
        existing = db.query(User).filter(User.username == username).first()
        if existing:
            return jsonify({'success': False, 'message': 'username å·²å­˜åœ¨'}), 400

        hashed = generate_password_hash(password)
        user = User(username=username, password_hash=hashed, display_name=display_name)
        # assign stores if exist. Accept either a Store.store_key (legacy) or
        # an Inventory.store name. We try to map the provided value to an
        # existing Store by exact match, prefix match, or by creating a
        # provisional store_key if nothing matches.
        for sk in stores:
            store = db.query(Store).filter(Store.store_key == sk).first()
            if not store:
                # try prefix/pattern match (e.g., inventory name matches the
                # left part of store_key like 'å°åŒ—å¤©æ–‡é¤¨ å·¦é‚Š' -> 'å°åŒ—å¤©æ–‡é¤¨ å·¦é‚Š-...')
                store = db.query(Store).filter(Store.store_key.like(f"{sk}%")).first()
            if not store:
                # fallback: create a provisional store entry using a common suffix
                new_key = f"{sk}-provisional_sales"
                store = db.query(Store).filter(Store.store_key == new_key).first()
                if not store:
                    store = Store(store_key=new_key)
                    db.add(store)
                    db.flush()
            if store:
                user.stores.append(store)

        db.add(user)
        db.commit()
        db.refresh(user)
        return jsonify({'success': True, 'user': user.to_dict()})
    except Exception as e:
        db.rollback()
        logging.error(f"Error creating user: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500
    finally:
        db.close()


@app.route('/api/user-login', methods=['POST'])
def api_user_login():
    """User login for presentation page. JSON: {username, password} sets session['user_id'] on success."""
    data = request.get_json() or {}
    username = data.get('username')
    password = data.get('password')
    if not username or not password:
        return jsonify({'success': False, 'message': 'username/password required'}), 400

    db: Session = next(get_db())
    try:
        user = db.query(User).filter(User.username == username).first()
        if not user or not check_password_hash(user.password_hash, password):
            return jsonify({'success': False, 'message': 'å¸³è™Ÿæˆ–å¯†ç¢¼éŒ¯èª¤'}), 401
        # set session user id; keep admin separate
        session['user_id'] = user.id
        return jsonify({'success': True, 'user': user.to_dict()})
    except Exception as e:
        logging.error(f"Error during user login: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500
    finally:
        db.close()


@app.route('/api/user-logout', methods=['POST'])
def api_user_logout():
    session.pop('user_id', None)
    return jsonify({'success': True})


@app.route('/api/user-info', methods=['GET'])
def api_user_info():
    user_id = session.get('user_id')
    if not user_id:
        return jsonify({'logged_in': False}), 200
    db: Session = next(get_db())
    try:
        user = db.query(User).filter(User.id == int(user_id)).first()
        if not user:
            return jsonify({'logged_in': False}), 200
        return jsonify({'logged_in': True, 'user': user.to_dict()})
    except Exception as e:
        logging.error(f"Error fetching user info: {e}")
        return jsonify({'logged_in': False}), 500
    finally:
        db.close()


@app.route('/presentation-login', methods=['GET'])
def presentation_login_page():
    """Serve a standalone presentation login page for franchisee users.

    The page posts to /api/user-login via fetch and redirects back to
    /presentation.html on success. A `next` query parameter is accepted.
    """
    return send_from_directory(script_dir, 'presentation_login.html')


@app.route('/presentation-logout', methods=['POST'])
def presentation_logout():
    """Optional helper to log out a franchisee and return JSON."""
    session.pop('user_id', None)
    return jsonify({'success': True})


@app.route('/api/user-profile', methods=['GET', 'POST'])
def api_user_profile():
    """Get or update the current logged-in user's profile (display_name, email).

    GET -> {logged_in, user}
    POST -> accepts JSON {displayName, email} and updates DB
    """
    user_id = session.get('user_id')
    if not user_id:
        return jsonify({'success': False, 'message': 'æœªç™»å…¥'}), 401

    db: Session = next(get_db())
    try:
        user = db.query(User).filter(User.id == int(user_id)).first()
        if not user:
            return jsonify({'success': False, 'message': 'user not found'}), 404

        if request.method == 'GET':
            return jsonify({'success': True, 'user': user.to_dict()})

        # POST -> update
        data = request.get_json() or {}
        display_name = data.get('displayName')
        email = data.get('email')
        low_threshold = data.get('lowInventoryThreshold')
        changed = False
        if display_name is not None:
            user.display_name = display_name
            changed = True
        if email is not None:
            user.email = email
            changed = True
        if low_threshold is not None:
            try:
                user.low_inventory_threshold = int(low_threshold)
                changed = True
            except Exception:
                pass
        if changed:
            db.add(user)
            db.commit()
            db.refresh(user)
        return jsonify({'success': True, 'user': user.to_dict()})
    except Exception as e:
        db.rollback()
        logging.error(f"Error in user-profile: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500
    finally:
        db.close()


@app.route('/api/user-change-password', methods=['POST'])
def api_user_change_password():
    """Change the logged-in user's password. JSON {currentPassword, newPassword}.
    Verifies current password and updates stored hash.
    """
    user_id = session.get('user_id')
    if not user_id:
        return jsonify({'success': False, 'message': 'æœªç™»å…¥'}), 401

    data = request.get_json() or {}
    current = data.get('currentPassword') or ''
    new = data.get('newPassword') or ''
    if not current or not new:
        return jsonify({'success': False, 'message': 'currentPassword and newPassword are required'}), 400
    if len(new) < 8:
        return jsonify({'success': False, 'message': 'æ–°å¯†ç¢¼é•·åº¦è‡³å°‘ 8 å­—å…ƒ'}), 400

    db: Session = next(get_db())
    try:
        user = db.query(User).filter(User.id == int(user_id)).first()
        if not user:
            return jsonify({'success': False, 'message': 'user not found'}), 404
        # verify current password
        if not check_password_hash(user.password_hash, current):
            return jsonify({'success': False, 'message': 'ç›®å‰å¯†ç¢¼éŒ¯èª¤'}), 403

        # update
        user.password_hash = generate_password_hash(new)
        db.add(user)
        db.commit()
        return jsonify({'success': True})
    except Exception as e:
        db.rollback()
        logging.error(f"Error changing password: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500
    finally:
        db.close()


def send_email_if_configured(to_email, subject, body, html_content=False):
    smtp_server = os.getenv('SMTP_SERVER')
    smtp_port = int(os.getenv('SMTP_PORT', '587'))
    smtp_user = os.getenv('SMTP_USER')
    smtp_pass = os.getenv('SMTP_PASS')
    from_email = os.getenv('FROM_EMAIL') or smtp_user
    if not smtp_server or not to_email or not from_email:
        logging.warning(f"Email not sent (missing config): smtp={smtp_server} to={to_email} from={from_email}")
        return {'ok': False, 'error': 'SMTP or from/to address missing'}
    try:
        msg = EmailMessage()
        msg['Subject'] = subject
        msg['From'] = from_email
        msg['To'] = to_email
        # Support HTML content when requested. Provide a plain-text fallback.
        if html_content:
            # Simple plain-text fallback; avoid stripping HTML aggressively here.
            fallback = 'æ­¤éƒµä»¶åŒ…å« HTML å…§å®¹ï¼Œè«‹ä½¿ç”¨æ”¯æ´ HTML çš„éƒµä»¶å®¢æˆ¶ç«¯æŸ¥çœ‹ã€‚'
            msg.set_content(fallback)
            msg.add_alternative(body, subtype='html')
        else:
            msg.set_content(body)

        # Connect and send via TLS (SendGrid uses TLS on 587)
        with smtplib.SMTP(smtp_server, smtp_port, timeout=10) as s:
            s.ehlo()
            try:
                s.starttls()
                s.ehlo()
            except Exception:
                logging.debug('starttls not supported or failed, continuing without it')
            if smtp_user and smtp_pass:
                try:
                    s.login(smtp_user, smtp_pass)
                except Exception as e:
                    logging.error(f"SMTP login failed for {smtp_user}: {e}")
                    return {'ok': False, 'error': f'SMTP login failed: {e}'}
            s.send_message(msg)
        logging.info(f"Sent email to {to_email} from {from_email} via {smtp_server}:{smtp_port}")
        return {'ok': True}
    except Exception as e:
        logging.error(f"Failed to send email to {to_email}: {e}", exc_info=True)
        return {'ok': False, 'error': str(e)}


@app.route('/api/notify-low-inventory', methods=['POST'])
def api_notify_low_inventory():
    """Manual trigger: check all users and send notification to those below threshold.

    This can be used in a scheduled job; here it's exposed for testing.
    """
    result = _notify_low_inventory_internal()
    if result.get('error'):
        return jsonify({'success': False, 'message': result['error']}), 500
    return jsonify({'success': True, 'notifications': result.get('notifications', [])})
    

def _notify_low_inventory_internal():
    db: Session = next(get_db())
    notifications = []
    # Daily limits and tracking
    DAILY_EMAIL_LIMIT = int(os.getenv('DAILY_EMAIL_LIMIT', '100'))
    emails_sent_today = 0
    # compute today's reset boundary at 16:00 UTC (which corresponds to Taiwan midnight)
    # This means notifications are considered "same day" if sent after the previous 16:00 UTC.
    from datetime import datetime, timedelta
    now_utc = datetime.utcnow()
    # reset happens at 16:00 UTC each UTC day
    reset_hour_utc = 16
    today_start = now_utc.replace(hour=reset_hour_utc, minute=0, second=0, microsecond=0)
    if now_utc.hour < reset_hour_utc:
        # If current UTC time is before 16:00, the 'today' start is the previous day's 16:00
        today_start = today_start - timedelta(days=1)
    try:
        users = db.query(User).all()
        logging.info(f'Checking low-inventory for {len(users)} users')
        for u in users:
            try:
                thresh = int(u.low_inventory_threshold or 0)
            except Exception:
                thresh = 0
            if not u.email or thresh <= 0:
                logging.debug(f"Skipping user {u.username}: no email or threshold={thresh}")
                continue
            # Check each assigned store individually (single-machine total), and notify if any store <= threshold
            low_stores = []
            for s in u.stores:
                # Respect the authoritative Store.is_hidden value from the DB (admin may toggle this)
                try:
                    db_store = db.query(Store).filter(Store.store_key == s.store_key).first()
                except Exception:
                    db_store = None

                if db_store and getattr(db_store, 'is_hidden', False):
                    logging.debug(f"Skipping hidden store {s.store_key} for user {u.username} because is_hidden")
                    continue

                left = s.store_key.split('-')[0]
                qty_rows = db.query(Inventory).filter(Inventory.store.ilike(f"%{left}%")).with_entities(Inventory.quantity).all()
                total_for_store = sum([q[0] or 0 for q in qty_rows])

                # Only log and include stores that are actually below threshold
                if total_for_store <= thresh:
                    logging.info(f"User {u.username} store {s.store_key} totalQuantity={total_for_store} threshold={thresh}")
                    # Prepare display name without provisional suffix
                    display_name = s.store_key
                    if display_name.endswith('-provisional_sales'):
                        display_name = display_name.replace('-provisional_sales', '')
                    low_stores.append({'store_key': s.store_key, 'display': display_name, 'total': total_for_store})

            if low_stores:
                # Filter out stores that have already triggered a notification for this user today
                filtered_low_stores = []
                for ls in low_stores:
                    already = db.query(NotificationSent).filter(
                        NotificationSent.user_id == u.id,
                        NotificationSent.store_key == ls['store_key'],
                        NotificationSent.sent_at >= today_start
                    ).first()
                    if not already:
                        filtered_low_stores.append(ls)

                if not filtered_low_stores:
                    logging.debug(f"User {u.username}: all low stores already notified today; skipping.")
                    continue

                # Check global daily limit
                if emails_sent_today >= DAILY_EMAIL_LIMIT:
                    logging.warning(f"Daily email limit reached ({DAILY_EMAIL_LIMIT}). Skipping notifications.")
                    break

                # We'll send one email per user containing ALL current low_stores (for context),
                # but only record NotificationSent for the newly-notified stores (filtered_low_stores).
                # Compose a single email listing all low stores for this user
                subject = f"ã€SWSADã€‘åº«å­˜é€šçŸ¥ - {len(filtered_low_stores)} å€‹æ©Ÿå°éœ€è¦æ‚¨çš„é—œæ³¨"

                # ä½¿ç”¨ HTML æ ¼å¼
                body_html_lines = [
                    f"<!DOCTYPE html><html><body>",
                    f"<h1 style='text-align:center; font-weight:bold;'>SWSAD</h1>",
                    f"<p>è¦ªæ„›çš„ {u.display_name or u.username}ï¼Œ</p>",
                    f"<p>é€™æ˜¯ä¸€å‰‡ä¾†è‡ªSWSADå°å¹«æ‰‹çš„é€šçŸ¥ï¼š</p>",
                    f"<p>ç³»çµ±ç™¼ç¾æœ‰å¹¾å°æ©Ÿå™¨çš„åº«å­˜å·²ç¶“ä½æ–¼æ‚¨è¨­å®šçš„è­¦æˆ’å€¼å›‰ï¼ç‚ºäº†ç¢ºä¿éŠ·å”®ä¸ä¸­æ–·ï¼Œå»ºè­°æ‚¨ç›¡å¿«å®‰æ’è£œè²¨ã€‚</p>",
                    
                    # é–‹å§‹å»ºç«‹è¡¨æ ¼
                    f"<table style='width:100%; border-collapse:collapse; text-align:left;'>",
                    f"   <tr style='background-color:#f2f2f2;'>",
                    f"       <th style='padding:8px; border:1px solid #ddd;'>æ©Ÿå°åç¨±</th>",
                    f"       <th style='padding:8px; border:1px solid #ddd;'>ç›®å‰åº«å­˜</th>",
                    f"   </tr>"
                ]

                for ls in low_stores:
                    # æ¯ä¸€è¡Œè³‡æ–™
                    body_html_lines.append(f"<tr>")
                    body_html_lines.append(f"    <td style='padding:8px; border:1px solid #ddd;'>{ls.get('display', ls['store_key'])}</td>")
                    body_html_lines.append(f"    <td style='padding:8px; border:1px solid #ddd;'>{ls['total']} å€‹</td>")
                    body_html_lines.append(f"</tr>")
                    
                body_html_lines.extend([
                    f"</table>", # è¡¨æ ¼çµæŸ
                    
                    f"<p>é»æ“Šä¸‹æ–¹é€£çµï¼Œå³å¯å‰å¾€ç¶²ç«™æŸ¥çœ‹è©³ç´°åº«å­˜ç‹€æ³ä¸¦å®‰æ’è£œè²¨ï¼š</p>",
                    f'<p><a href="https://swsad3.onrender.com/presentation">ğŸ‘‰ æ™ºæ…§å€‰å„²èˆ‡éŠ·å”®åˆ†æå„€è¡¨æ¿-Smart Warehousing and Sales Analysis Dashboard</a></p>',
                    f"<p>æ­¤ç‚ºç³»çµ±è‡ªå‹•é€šçŸ¥ï¼Œè«‹å‹¿å›è¦†ã€‚</p>",
                    f"</body></html>"
                ])

                body_html = "\n".join(body_html_lines)
                send_result = send_email_if_configured(u.email, subject, body_html, html_content=True)
                # If sent successfully (or attempted), record sent notifications for each newly-notified store only
                try:
                    for ls in filtered_low_stores:
                        ns = NotificationSent(user_id=u.id, store_key=ls['store_key'])
                        db.add(ns)
                    db.commit()
                except Exception as e:
                    db.rollback()
                    logging.error(f"Failed to record NotificationSent: {e}", exc_info=True)

                emails_sent_today += 1
                notifications.append({'user': u.username, 'email': u.email, 'lowStores': filtered_low_stores, 'allLowStores': low_stores, 'threshold': thresh, 'sent': send_result})
            else:
                logging.debug(f"User {u.username} has no assigned stores below threshold {thresh}")
        return {'notifications': notifications}
    except Exception as e:
        logging.error(f"Error in notify-low-inventory internal: {e}", exc_info=True)
        return {'error': str(e)}
    finally:
        db.close()


@app.route('/api/notify-low-inventory/trigger', methods=['GET'])
def api_notify_low_inventory_trigger():
    """Convenience GET endpoint to trigger low-inventory notifications (for testing via browser)."""
    result = _notify_low_inventory_internal()
    if result.get('error'):
        return jsonify({'success': False, 'message': result['error']}), 500
    return jsonify({'success': True, 'notifications': result.get('notifications', [])})


# Serve presentation page but redirect unauthenticated users to the presentation login
@app.route('/presentation.html', methods=['GET'])
def presentation_page():
    user_id = session.get('user_id')
    if not user_id:
        # Redirect to presentation-login and include next param
        return redirect(f"/presentation-login?next=/presentation.html")
    return send_from_directory(script_dir, 'presentation.html')


@app.route('/presentation', methods=['GET'])
def presentation_short():
    return redirect('/presentation.html')

@app.route('/api/update-logs', methods=['GET'])
def get_update_logs():
    """Returns the last 50 update log entries, newest first."""
    db: Session = next(get_db())
    try:
        logs = db.query(UpdateLog).order_by(UpdateLog.ran_at.desc()).limit(50).all()
        result = [
            {
                "scraperType": log.scraper_type,
                "ranAt": log.ran_at.isoformat(),
                "status": log.status,
                "details": log.details
            }
            for log in logs
        ]
        return jsonify(result)
    except Exception as e:
        logging.error(f"Error getting update logs: {e}", exc_info=True)
        return jsonify({"error": "Could not retrieve update logs"}), 500
    finally:
        db.close()

@app.route('/api/stores/<string:store_key>', methods=['POST'])
def update_store_data(store_key):
    """
    Updates the custom data for a specific store (address, note, sales, hidden status).
    This is the new endpoint for saving user edits.
    """
    data = request.get_json()
    if not data:
        return jsonify({"success": False, "message": "No data provided"}), 400

    db: Session = next(get_db())
    try:
        store = db.query(Store).filter(Store.store_key == store_key).first()
        
        if not store:
            store = Store(store_key=store_key)
            db.add(store)
        
        if 'address' in data:
            store.address = data['address']
        if 'note' in data:
            store.note = data['note']
        if 'manualSales' in data:
            store.manual_sales = data['manualSales']
        if 'isHidden' in data:
            store.is_hidden = data['isHidden']
            
        db.commit()
        db.refresh(store)
        
        return jsonify({"success": True, "data": store.to_dict()})
        
    except Exception as e:
        db.rollback()
        return jsonify({"success": False, "message": str(e)}), 500
    finally:
        db.close()

@app.route('/api/transactions', methods=['POST'])
def add_transactions():
    """
    Receives a list of transactions, clears existing ones, and saves the new ones.
    Includes a retry mechanism for database operations.
    """
    transactions_data = request.get_json()
    if not isinstance(transactions_data, list):
        return jsonify({"success": False, "message": "Invalid data format. Expected a list of transactions."}), 400

    max_retries = 3
    retry_delay_seconds = 5
    for attempt in range(max_retries):
        db: Session = next(get_db())
        try:
            # Clear existing transactions
            db.query(Transaction).delete()
            logging.info("Cleared existing transactions.")
            
            new_transactions = []
            
            all_stores = db.query(Store).all()
            store_name_map = {}
            for s in all_stores:
                name_parts = s.store_key.rsplit('-', 1)
                name = name_parts[0]
                if name not in store_name_map:
                    store_name_map[name] = s

            for item in transactions_data:
                shop_name_raw = item.get('shopName')
                if not shop_name_raw or not item.get('date'):
                    continue
                
                shop_name = shop_name_raw.strip()
                store = store_name_map.get(shop_name)
                
                if not store:
                    logging.info(f"Shop '{shop_name}' not found in DB. Creating a new provisional store.")
                    new_store_key = f"{shop_name}-provisional_sales"
                    
                    existing_provisional = db.query(Store).filter(Store.store_key == new_store_key).first()
                    if existing_provisional:
                        store = existing_provisional
                    else:
                        store = Store(store_key=new_store_key)
                        db.add(store)
                        db.flush()
                    
                    store_name_map[shop_name] = store

                new_transactions.append(Transaction(
                    store_key=store.store_key,
                    transaction_time=parse_date(item.get('date')),
                    amount=int(float(item.get('amount', 0))),
                    product_name=item.get('product'),
                    payment_type=item.get('payType')
                ))

            if new_transactions:
                db.bulk_save_objects(new_transactions)
                logging.info(f"Preparing to save {len(new_transactions)} new transactions.")
            
            db.commit()
            logging.info("Successfully committed transactions.")
            db.close()
            return jsonify({"success": True, "message": f"Successfully added {len(new_transactions)} transactions."})

        except OperationalError as e:
            db.rollback()
            db.close()
            logging.error(f"DB Error on attempt {attempt + 1}: {e}")
            if attempt + 1 >= max_retries:
                logging.error("Max retries reached. Aborting.")
                return jsonify({"success": False, "message": f"Database error after {max_retries} attempts: {e}"}), 500
            logging.info(f"Retrying in {retry_delay_seconds} seconds...")
            time.sleep(retry_delay_seconds)
        except Exception as e:
            db.rollback()
            db.close()
            logging.error(f"Error adding transactions: {e}")
            traceback.print_exc()
            return jsonify({"success": False, "message": str(e)}), 500
        finally:
            if 'db' in locals() and db.is_active:
                db.close()


@app.route('/upload-warehouse-file', methods=['POST'])
def upload_warehouse_file():
    """
    æ¥æ”¶å€‰åº«åº«å­˜ Excel æ–‡ä»¶ä¸¦ä¿å­˜åˆ°æ•¸æ“šåº«
    åªæ›¿æ›åŒåå€‰åº«çš„æ•¸æ“šï¼Œä¸åŒå€‰åº«çš„æ•¸æ“šæœƒä¿ç•™
    """
    try:
        if 'file' not in request.files:
            return jsonify({'success': False, 'message': 'æ²’æœ‰é¸æ“‡æ–‡ä»¶'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'success': False, 'message': 'æ²’æœ‰é¸æ“‡æ–‡ä»¶'}), 400
        
        # æª¢æŸ¥æ–‡ä»¶é¡å‹
        if not file.filename.endswith(('.xlsx', '.xls')):
            return jsonify({'success': False, 'message': 'åªæ”¯æŒ Excel æ ¼å¼çš„æ–‡ä»¶ (.xlsx, .xls)'}), 400
        
        # è®€å– Excel æ–‡ä»¶
        df = pd.read_excel(file)
        required_columns = ['Warehouse name', 'Product name', 'Remain quantity']
        
        # é©—è­‰å¿…è¦æ¬„ä½
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            return jsonify({
                'success': False, 
                'message': f'ç¼ºå°‘å¿…è¦æ¬„ä½: {", ".join(missing_columns)}'
            }), 400
        
        # è³‡æ–™è™•ç†å’Œé©—è­‰
        df['Remain quantity'] = pd.to_numeric(df['Remain quantity'], errors='coerce')
        df = df.dropna(subset=['Warehouse name', 'Product name', 'Remain quantity'])
        
        # æ›´æ–°è³‡æ–™åº«
        max_retries = 3
        retry_delay_seconds = 5
        
        for attempt in range(max_retries):
            db: Session = next(get_db())
            try:
                # ç²å–è¦æ›´æ–°çš„å€‰åº«åˆ—è¡¨
                warehouse_names = df['Warehouse name'].unique()
                
                # åªåˆªé™¤è¦æ›´æ–°çš„å€‰åº«çš„æ•¸æ“š
                for warehouse in warehouse_names:
                    db.query(Warehouse).filter(Warehouse.warehouse_name == warehouse).delete()
                
                # å‰µå»ºæ–°çš„å€‰åº«è¨˜éŒ„
                warehouse_records = []
                for _, row in df.iterrows():
                    warehouse_records.append(Warehouse(
                        warehouse_name=str(row['Warehouse name']),
                        product_name=str(row['Product name']),
                        quantity=int(row['Remain quantity']),
                        updated_at=datetime.now(pytz.timezone('Asia/Taipei'))
                    ))
                
                db.bulk_save_objects(warehouse_records)
                db.commit()
                
                return jsonify({
                    'success': True,
                    'message': f'æˆåŠŸä¸Šå‚³ä¸¦è™•ç† {len(warehouse_records)} ç­†å€‰åº«æ•¸æ“š',
                    'records_count': len(warehouse_records)
                })
                
            except OperationalError as e:
                db.rollback()
                logging.error(f"Database error on attempt {attempt + 1}/{max_retries}: {e}")
                if attempt + 1 >= max_retries:
                    return jsonify({'success': False, 'message': f'æ•¸æ“šåº«éŒ¯èª¤: {str(e)}'}), 500
                time.sleep(retry_delay_seconds)
            except Exception as e:
                db.rollback()
                logging.error(f"Error processing warehouse file: {e}", exc_info=True)
                return jsonify({'success': False, 'message': f'è™•ç†æ–‡ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}'}), 500
            finally:
                db.close()
                
    except Exception as e:
        logging.error(f"Error in warehouse file upload: {e}", exc_info=True)
        return jsonify({'success': False, 'message': f'æ–‡ä»¶ä¸Šå‚³å¤±æ•—: {str(e)}'}), 500

@app.route('/api/warehouses', methods=['GET'])
def get_warehouses():
    """
    ç²å–æ‰€æœ‰å€‰åº«æ•¸æ“š
    """
    db: Session = next(get_db())
    try:
        logging.info("Fetching warehouse data from database...")
        warehouses = db.query(Warehouse).all()
        logging.info(f"Found {len(warehouses)} warehouse records")
        
        result = [{
            'warehouseName': w.warehouse_name,
            'productName': w.product_name,
            'quantity': w.quantity,
            'updatedAt': w.updated_at.isoformat() if w.updated_at else None
        } for w in warehouses]
        
        logging.info(f"Returning {len(result)} warehouse records")
        return jsonify(result)
    except Exception as e:
        logging.error(f"Error getting warehouses: {e}", exc_info=True)
        return jsonify({"error": "Could not retrieve warehouse data"}), 500
    finally:
        db.close()

@app.route('/api/warehouse-replenishment-suggestion/<string:store_key>', methods=['POST'])
def get_warehouse_replenishment_suggestion(store_key):
    """
    æ–°çš„è£œè²¨å»ºè­° APIï¼Œå°ˆé–€ç”¨æ–¼è£œè²¨åˆ†é ï¼Œè€ƒæ…®å€‰åº«åº«å­˜
    """
    data = request.get_json()
    if not data:
        return jsonify({"success": False, "message": "No data provided"}), 400

    selected_warehouses = data.get("warehouses", [])
    if not selected_warehouses:
        return jsonify({
            "success": False,
            "message": "è«‹é¸æ“‡è‡³å°‘ä¸€å€‹å€‰åº«"
        }), 400

    strategy = data.get("strategy", "stable")
    machine_capacity = int(data.get("max_total_qty", 50))
    if machine_capacity < 1 or machine_capacity > 50:
        machine_capacity = 50

    db: Session = next(get_db())
    try:
        store_name, machine_id = store_key.split('-', 1)
        
        # 1. ç²å–å€‰åº«åº«å­˜æ•¸æ“š
        warehouse_inventory = {}
        for warehouse_name in selected_warehouses:
            warehouse_items = db.query(Warehouse).filter_by(warehouse_name=warehouse_name).all()
            for item in warehouse_items:
                if item.product_name in warehouse_inventory:
                    warehouse_inventory[item.product_name] += item.quantity
                else:
                    warehouse_inventory[item.product_name] = item.quantity

        if not warehouse_inventory:
            return jsonify({
                "success": False,
                "message": "é¸æ“‡çš„å€‰åº«ä¸­æ²’æœ‰å¯ç”¨åº«å­˜"
            }), 400

        # 2. ç²å–æ©Ÿå°ç•¶å‰åº«å­˜
        inventory_items = db.query(Inventory).filter_by(store=store_name, machine_id=machine_id).all()
        current_inventory = {item.product_name: item.quantity for item in inventory_items}

        # 3. ç²å–éŠ·å”®æ•¸æ“š
        thirty_days_ago = datetime.now() - timedelta(days=30)
        transactions = db.query(Transaction).filter(
            Transaction.store_key.startswith(store_name),
            Transaction.transaction_time >= thirty_days_ago
        ).all()

        sales_counts = {}
        for t in transactions:
            if t.product_name:
                sales_counts[t.product_name] = sales_counts.get(t.product_name, 0) + 1

        # 4. æ ¹æ“šç­–ç•¥ç”Ÿæˆå»ºè­°
        suggestion_list = []
        warning = None

        # æ ¹æ“šä¸åŒç­–ç•¥ç”Ÿæˆå»ºè­°
        if strategy == 'stable':
            # ç©©å¥ç­–ç•¥ï¼šæ ¹æ“šéŠ·é‡æ¯”ä¾‹åˆ†é…å‰©é¤˜ç©ºé–“
            sales_products = []
            current_total = sum(current_inventory.values())  # ç•¶å‰ç¸½æ•¸
            remaining_space = machine_capacity - current_total  # å‰©é¤˜å¯ç”¨ç©ºé–“
            
            for product, warehouse_qty in warehouse_inventory.items():
                current_qty = current_inventory.get(product, 0)
                sales = sales_counts.get(product, 0)
                
                if warehouse_qty > 0:  # åªè€ƒæ…®å€‰åº«æœ‰åº«å­˜çš„ç”¢å“
                    sales_products.append({
                        'productName': product,
                        'currentQty': current_qty,
                        'warehouseQty': warehouse_qty,
                        'salesCount30d': sales,
                        'suggestedQty': current_qty  # åˆå§‹è¨­ç‚ºç•¶å‰æ•¸é‡
                    })
            
            if sales_products and remaining_space > 0:
                # æ ¹æ“šéŠ·é‡è¨ˆç®—é¡å¤–åˆ†é…
                total_sales = sum(p['salesCount30d'] for p in sales_products)
                products_to_add = [p for p in sales_products if p['warehouseQty'] > 0]
                
                if total_sales > 0 and products_to_add:
                    # æœ‰éŠ·é‡çš„ç”¢å“æŒ‰æ¯”ä¾‹åˆ†é…å‰©é¤˜ç©ºé–“
                    base_additions = []
                    for product in products_to_add:
                        ratio = product['salesCount30d'] / total_sales
                        addition = round(ratio * remaining_space)
                        base_additions.append((product, addition))
                        
                    # èª¿æ•´ä»¥ç¢ºä¿ç¸½æ•¸æ­£ç¢º
                    total_addition = sum(addition for _, addition in base_additions)
                    if total_addition != remaining_space:
                        diff = remaining_space - total_addition
                        # æŒ‰æ¯”ä¾‹èª¿æ•´å·®ç•°
                        for i, (product, _) in enumerate(base_additions):
                            if i < abs(diff):
                                base_additions[i] = (product, base_additions[i][1] + (1 if diff > 0 else -1))
                    
                    # æ‡‰ç”¨èª¿æ•´å¾Œçš„æ•¸é‡
                    for product, addition in base_additions:
                        product['suggestedQty'] = product['currentQty'] + addition
                else:
                    # ç„¡éŠ·é‡æ™‚å¹³å‡åˆ†é…å‰©é¤˜ç©ºé–“
                    base_qty = remaining_space // len(products_to_add)
                    remainder = remaining_space % len(products_to_add)
                    for i, product in enumerate(products_to_add):
                        addition = base_qty + (1 if i < remainder else 0)
                        product['suggestedQty'] = product['currentQty'] + addition
                
                suggestion_list.extend(sales_products)

        elif strategy == 'aggressive':
            # ç©æ¥µç­–ç•¥ï¼šå„ªå…ˆåˆ†é…çµ¦ç†±éŠ·å“ï¼Œç¢ºä¿ç¸½é‡ç‚º50
            current_total = sum(current_inventory.values())
            remaining_space = machine_capacity - current_total
            
            # å…ˆåŠ å…¥æ‰€æœ‰ç¾æœ‰ç”¢å“
            suggestion_list = [{
                'productName': product,
                'currentQty': qty,
                'suggestedQty': qty,  # åˆå§‹è¨­ç‚ºç•¶å‰æ•¸é‡
                'warehouseQty': warehouse_inventory.get(product, 0),
                'salesCount30d': sales_counts.get(product, 0)
            } for product, qty in current_inventory.items()]
            
            # æ ¹æ“šéŠ·é‡æ’åºæ‰€æœ‰å¯èƒ½çš„æ–°å¢ç”¢å“
            available_products = [(p, warehouse_inventory.get(p, 0), sales_counts.get(p, 0))
                                for p in warehouse_inventory.keys()
                                if p not in current_inventory and warehouse_inventory.get(p, 0) > 0]
            
            sorted_products = sorted(available_products,
                                  key=lambda x: x[2],  # æŒ‰éŠ·é‡æ’åº
                                  reverse=True)
            
            if remaining_space > 0 and sorted_products:
                # æ–°ç”¢å“ä¸­çš„å‰3ååˆ†é…80%çš„å‰©é¤˜ç©ºé–“
                top_3 = sorted_products[:3]
                top_3_space = round(remaining_space * 0.8)
                base_qty = top_3_space // len(top_3)
                remainder = top_3_space % len(top_3)
                
                for i, (product, warehouse_qty, sales) in enumerate(top_3):
                    suggested_qty = base_qty + (1 if i < remainder else 0)
                    suggestion_list.append({
                        'productName': product,
                        'currentQty': 0,
                        'suggestedQty': suggested_qty,
                        'warehouseQty': warehouse_qty,
                        'salesCount30d': sales
                    })
            
            # å‰©é¤˜ç”¢å“åˆ†é…å‰©é¤˜ç©ºé–“
            other_products = sorted_products[3:]
            remaining_space_for_others = remaining_space - top_3_space
            
            if other_products and remaining_space_for_others > 0:
                base_qty = remaining_space_for_others // len(other_products)
                remainder = remaining_space_for_others % len(other_products)
                
                for i, (product, warehouse_qty, sales) in enumerate(other_products):
                    suggested_qty = base_qty + (1 if i < remainder else 0)
                    suggestion_list.append({
                        'productName': product,
                        'currentQty': 0,
                        'suggestedQty': suggested_qty,
                        'warehouseQty': warehouse_qty,
                        'salesCount30d': sales
                    })

        else:  # exploratory
            # æ¢ç´¢ç­–ç•¥ï¼š80%ç©ºé–“çµ¦ç¾æœ‰ç”¢å“ï¼Œ20%çµ¦æ–°ç”¢å“
            suggestion_list = []
            current_total = sum(current_inventory.values())
            remaining_space = machine_capacity - current_total
            
            # å…ˆåŠ å…¥æ‰€æœ‰ç¾æœ‰ç”¢å“
            for product, qty in current_inventory.items():
                suggestion_list.append({
                    'productName': product,
                    'currentQty': qty,
                    'suggestedQty': qty,  # ä¿æŒç•¶å‰æ•¸é‡
                    'warehouseQty': warehouse_inventory.get(product, 0),
                    'salesCount30d': sales_counts.get(product, 0)
                })
            
            if remaining_space > 0:
                # è™•ç†æœ‰éŠ·é‡ä½†ä¸åœ¨ç•¶å‰åº«å­˜çš„ç”¢å“ï¼ˆä½”å‰©é¤˜ç©ºé–“çš„80%ï¼‰
                existing_space = round(remaining_space * 0.8)
                sales_products = [(p, warehouse_inventory[p], sales_counts.get(p, 0))
                                for p in warehouse_inventory.keys()
                                if p not in current_inventory and sales_counts.get(p, 0) > 0 and warehouse_inventory[p] > 0]
                
                if sales_products:
                    base_qty = existing_space // len(sales_products)
                    remainder = existing_space % len(sales_products)
                    
                    for i, (product, warehouse_qty, sales) in enumerate(sales_products):
                        suggested_qty = base_qty + (1 if i < remainder else 0)
                        suggestion_list.append({
                            'productName': product,
                            'currentQty': 0,
                            'suggestedQty': suggested_qty,
                            'warehouseQty': warehouse_qty,
                            'salesCount30d': sales
                        })
            
            # è™•ç†æ–°ç”¢å“ï¼ˆæ²’æœ‰éŠ·é‡çš„ç”¢å“ï¼‰
            new_space = remaining_space - existing_space  # å‰©é¤˜20%ç©ºé–“çµ¦æ–°ç”¢å“
            new_products = [(p, warehouse_inventory[p])
                          for p in warehouse_inventory.keys()
                          if p not in current_inventory and p not in [x['productName'] for x in suggestion_list] 
                          and warehouse_inventory[p] > 0]
            
            if new_products and new_space > 0:
                base_qty = new_space // len(new_products)
                remainder = new_space % len(new_products)
                
                for i, (product, warehouse_qty) in enumerate(new_products):
                    suggested_qty = base_qty + (1 if i < remainder else 0)
                    suggestion_list.append({
                        'productName': product,
                        'currentQty': 0,
                        'suggestedQty': suggested_qty,
                        'warehouseQty': warehouse_qty,
                        'salesCount30d': 0
                    })        # 5. æ’åºä¸¦è¿”å›çµæœ
        suggestion_list.sort(key=lambda x: (x['suggestedQty'] - x['currentQty']), reverse=True)
        
        return jsonify({
            "success": True,
            "store_key": store_key,
            "strategy_used": strategy,
            "suggestion": suggestion_list,
            "warning": warning,
            "warehouse_info": [{
                "name": w,
                "products": len([p for p in warehouse_inventory if w in selected_warehouses])
            } for w in selected_warehouses]
        })

    except Exception as e:
        logging.error(f"Error generating warehouse replenishment suggestion: {e}", exc_info=True)
        return jsonify({
            "success": False,
            "message": f"ç”Ÿæˆè£œè²¨å»ºè­°æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
        }), 500
    finally:
        db.close()

@app.route('/api/transactions', methods=['GET'])
def get_transactions():
    """
    Returns all transactions in the format expected by presentation.html.
    """
    db: Session = next(get_db())
    try:
        # If a user is logged in, restrict transactions to user's assigned stores
        user_id = session.get('user_id')
        transactions_query = db.query(Transaction)
        if user_id:
            user = db.query(User).filter(User.id == int(user_id)).first()
            if user:
                user_store_keys = [s.store_key for s in user.stores]
                # build filters similar to inventory matching
                trans_filters = []
                for sk in user_store_keys:
                    if '-' in sk:
                        left = sk.rsplit('-', 1)[0]
                        trans_filters.append(Transaction.store_key == sk)
                        trans_filters.append(Transaction.store_key.ilike(f"{left}%"))
                        trans_filters.append(Transaction.store_key.ilike(f"%{left}%"))
                    else:
                        trans_filters.append(Transaction.store_key.ilike(sk))
                        trans_filters.append(Transaction.store_key.ilike(f"%{sk}%"))
                if trans_filters:
                    transactions_query = transactions_query.filter(or_(*trans_filters))

        transactions = transactions_query.all()

        # Create a map of store_key to store_name for quick lookup
        stores = {s.store_key: s.store_key.rsplit('-', 1)[0] for s in db.query(Store).all()}

        result = [
            {
                "shopName": stores.get(t.store_key, t.store_key), # Fallback to store_key if not in map
                "date": t.transaction_time.isoformat(),
                "amount": t.amount,
                "product": t.product_name,
                "payType": t.payment_type,
            }
            for t in transactions
        ]
        return jsonify(result)
    except Exception as e:
        logging.error(f"Error getting transactions: {e}")
        traceback.print_exc()
        return jsonify({"success": False, "message": str(e)}), 500
    finally:
        db.close()


@app.route('/api/inventory/<store_key>', methods=['DELETE'])
def delete_inventory_data(store_key):
    """
    Deletes all inventory and custom data associated with a specific store_key.
    """
    if not store_key:
        return jsonify({"success": False, "message": "store_key is required"}), 400

    db: Session = next(get_db())
    try:
        store_name, machine_id = store_key.split('-', 1)

        db.query(Inventory).filter_by(store=store_name, machine_id=machine_id).delete(synchronize_session=False)
        db.query(Store).filter_by(store_key=store_key).delete(synchronize_session=False)
        db.query(Transaction).filter_by(store_key=store_key).delete(synchronize_session=False)

        db.commit()

        return jsonify({"success": True, "message": "Data deleted successfully."})

    except Exception as e:
        db.rollback()
        return jsonify({"success": False, "message": str(e)}), 500
    finally:
        db.close()


def distribute_remainder(items, total_slots):
    """
    ä¸€å€‹è¼”åŠ©å‡½æ•¸ï¼Œç”¨æ–¼è™•ç†è£œè²¨å»ºè­°æ•¸é‡è¨ˆç®—ä¸­çš„å°æ•¸å•é¡Œã€‚
    å®ƒæœƒç¢ºä¿æ‰€æœ‰ç”¢å“çš„å»ºè­°æ•¸é‡åŠ ç¸½å¾Œå‰›å¥½ç­‰æ–¼æ©Ÿå°çš„ç›®æ¨™ç¸½å®¹é‡ã€‚
    """
    # æ ¹æ“šå°æ•¸éƒ¨åˆ†ç”±å¤§åˆ°å°æ’åºï¼Œå°æ•¸è¶Šå¤§çš„è¶Šå„ªå…ˆç²å¾— +1
    items.sort(key=lambda x: x['suggestedQty_float'] - int(x['suggestedQty_float']), reverse=True)
    
    # è¨ˆç®—æ‰€æœ‰å“é …ç„¡æ¢ä»¶æ¨å»å¾Œçš„ç¸½å’Œ
    current_total = sum(int(item['suggestedQty_float']) for item in items)
    remainder = total_slots - current_total
    
    result = []
    for i, item in enumerate(items):
        qty = int(item['suggestedQty_float'])
        # å°‡é¤˜ä¸‹çš„æ•¸é‡é€ä¸€åˆ†é…çµ¦æ’åºæœ€å‰é¢çš„å“é …
        if i < remainder:
            qty += 1
        result.append({'productName': item['productName'], 'suggestedQty': qty, 'sales_count': item.get('sales_count', 0)})
    
    return result

@app.route('/api/replenishment-suggestion/<string:store_key>', methods=['POST'])
def get_replenishment_suggestion(store_key):
    """
    ç”Ÿæˆè£œè²¨å»ºè­°çš„æ ¸å¿ƒAPIã€‚
    æ¥æ”¶ç­–ç•¥å’Œé ç•™ç©ºä½ï¼Œå›å‚³ä¸€ä»½è©³ç´°çš„è£œè²¨æ¸…å–®ã€‚
    """
    data = request.get_json()
    if not data:
        return jsonify({"success": False, "message": "No data provided"}), 400

    strategy = data.get("strategy", "stable")
    reserve_slots = int(data.get("reserve_slots", 0))
    only_add = bool(data.get("only_add", False))
    machine_capacity = int(data.get("max_total_qty", 50))
    selected_warehouses = data.get("warehouses", [])
    
    if not selected_warehouses:
        return jsonify({
            "success": False,
            "message": "è«‹é¸æ“‡è‡³å°‘ä¸€å€‹å€‰åº«"
        }), 400

    if machine_capacity < 1 or machine_capacity > 50:
        machine_capacity = 50
    
    available_slots = machine_capacity - reserve_slots

    db: Session = next(get_db())
    try:
        store_name, machine_id = store_key.split('-', 1)
        
        # 1. ç²å–ç›®å‰åº«å­˜
        inventory_items = db.query(Inventory).filter_by(store=store_name, machine_id=machine_id).all()
        current_inventory = {item.product_name: item.quantity for item in inventory_items}

        # 2. ç²å–éå»30å¤©çš„éŠ·å”®æ•¸æ“š (æ­¤è™•å‡è¨­åŒåº—é‹ªåçš„æ‰€æœ‰æ©Ÿå°å…±äº«éŠ·å”®æ•¸æ“š)
        thirty_days_ago = datetime.now() - timedelta(days=30)
        transactions = db.query(Transaction).filter(
            Transaction.store_key.startswith(store_name),
            Transaction.transaction_time >= thirty_days_ago
        ).all()

        sales_counts = {}
        for t in transactions:
            if t.product_name:
                sales_counts[t.product_name] = sales_counts.get(t.product_name, 0) + 1
        
        total_sales_volume = sum(sales_counts.values())

        # 2.5 ç²å–æ‰€é¸å€‰åº«çš„åº«å­˜æ•¸æ“š
        warehouse_inventory = {}
        for warehouse_name in selected_warehouses:
            warehouse_items = db.query(Warehouse).filter_by(warehouse_name=warehouse_name).all()
            for item in warehouse_items:
                if item.product_name in warehouse_inventory:
                    warehouse_inventory[item.product_name] += item.quantity
                else:
                    warehouse_inventory[item.product_name] = item.quantity

        if not warehouse_inventory:
            return jsonify({
                "success": False,
                "message": "é¸æ“‡çš„å€‰åº«ä¸­æ²’æœ‰å¯ç”¨åº«å­˜"
            }), 400

        if total_sales_volume == 0:
            # å¦‚æœæ²’æœ‰éŠ·å”®æ•¸æ“šï¼Œå‰‡æ ¹æ“šå€‰åº«åº«å­˜æƒ…æ³æä¾›å»ºè­°
            available_products = list(warehouse_inventory.items())
            if strategy == 'stable':
                # å¹³å‡åˆ†é…å€‰åº«ä¸­æœ‰çš„å•†å“
                slots_per_product = available_slots // len(available_products)
                suggestion_list = [
                    {'productName': p, 'suggestedQty': min(slots_per_product, q)} 
                    for p, q in available_products
                ]
            elif strategy == 'aggressive':
                # æŒ‰å€‰åº«åº«å­˜é‡æ’åºï¼Œå„ªå…ˆåˆ†é…åº«å­˜é‡å¤§çš„å•†å“
                sorted_products = sorted(available_products, key=lambda x: x[1], reverse=True)
                top_products = sorted_products[:3]
                suggestion_list = [
                    {'productName': p, 'suggestedQty': min(round(available_slots * 0.3), q)} 
                    for p, q in top_products
                ]
            else:  # exploratory
                # å°‘é‡å˜—è©¦å€‰åº«ä¸­çš„æ‰€æœ‰å•†å“
                suggestion_list = [
                    {'productName': p, 'suggestedQty': min(2, q)} 
                    for p, q in available_products
                ]
            
            return jsonify({
                "success": True,
                "strategy_used": f"{strategy}_no_sales",
                "suggestion": suggestion_list,
                "message": "æ ¹æ“šå€‰åº«åº«å­˜ç”Ÿæˆå»ºè­°"
            })

        # 3. æ‡‰ç”¨ä¸åŒç­–ç•¥ï¼ˆè€ƒæ…®éŠ·å”®æ•¸æ“šå’Œå€‰åº«åº«å­˜ï¼‰
        suggestion_list = []
        # åªè€ƒæ…®å€‰åº«ä¸­æœ‰åº«å­˜çš„ç”¢å“çš„éŠ·å”®æ•¸æ“š
        filtered_sales = {
            product: count for product, count in sales_counts.items() 
            if product in warehouse_inventory
        }
        if not filtered_sales:
            return jsonify({
                "success": False,
                "message": "å€‰åº«ä¸­æ²’æœ‰ä»»ä½•æœ‰éŠ·å”®è¨˜éŒ„çš„ç”¢å“"
            }), 400
            
        total_filtered_sales = sum(filtered_sales.values())
        sorted_sales = sorted(filtered_sales.items(), key=lambda item: item[1], reverse=True)

        if strategy == 'stable':
            # ç©©å¥ç­–ç•¥ï¼šæ ¹æ“šéŠ·å”®æ¯”ä¾‹åˆ†é…ï¼Œä½†å—å€‰åº«åº«å­˜é™åˆ¶
            temp_suggestions = []
            for p, c in filtered_sales.items():
                suggested_qty = (c / total_filtered_sales) * available_slots
                # ç¢ºä¿ä¸è¶…éå€‰åº«åº«å­˜
                warehouse_qty = warehouse_inventory.get(p, 0)
                suggested_qty = min(suggested_qty, warehouse_qty)
                temp_suggestions.append({
                    'productName': p,
                    'suggestedQty_float': suggested_qty,
                    'sales_count': c,
                    'warehouse_qty': warehouse_qty
                })
            suggestion_list = distribute_remainder(temp_suggestions, available_slots)
        
        elif strategy == 'aggressive':
            # ç©æ¥µç­–ç•¥ï¼šå„ªå…ˆåˆ†é…éŠ·é‡å‰ä¸‰çš„ç”¢å“ï¼Œä½†å—å€‰åº«åº«å­˜é™åˆ¶
            top_3_products = sorted_sales[:3]
            other_products = sorted_sales[3:]
            
            slots_for_top_3 = round(available_slots * 0.8)
            slots_for_others = available_slots - slots_for_top_3
            
            temp_suggestions = []
            # è™•ç†å‰ä¸‰åç”¢å“
            for p, c in top_3_products:
                warehouse_qty = warehouse_inventory.get(p, 0)
                suggested_qty = min(slots_for_top_3 / len(top_3_products), warehouse_qty)
                temp_suggestions.append({
                    'productName': p,
                    'suggestedQty_float': suggested_qty,
                    'sales_count': c,
                    'warehouse_qty': warehouse_qty
                })
            
            # è™•ç†å…¶ä»–ç”¢å“
            if other_products:
                qty_per_other = slots_for_others / len(other_products)
                for p, c in other_products:
                    warehouse_qty = warehouse_inventory.get(p, 0)
                    suggested_qty = min(qty_per_other, warehouse_qty)
                    temp_suggestions.append({
                        'productName': p,
                        'suggestedQty_float': suggested_qty,
                        'sales_count': c,
                        'warehouse_qty': warehouse_qty
                    })
            
            suggestion_list = distribute_remainder(temp_suggestions, available_slots)

        elif strategy == 'exploratory':
            # æ¢ç´¢ç­–ç•¥ï¼šä¿ç•™20%ç©ºé–“çµ¦æ–°ç”¢å“ï¼Œå…¶é¤˜æ ¹æ“šéŠ·é‡åˆ†é…
            slots_for_existing = round(available_slots * 0.8)
            slots_for_new = available_slots - slots_for_existing

            # è™•ç†ç¾æœ‰ç”¢å“
            temp_suggestions = []
            for p, c in filtered_sales.items():
                warehouse_qty = warehouse_inventory.get(p, 0)
                suggested_qty = min(
                    (c / total_filtered_sales) * slots_for_existing,
                    warehouse_qty
                )
                temp_suggestions.append({
                    'productName': p,
                    'suggestedQty_float': suggested_qty,
                    'sales_count': c,
                    'warehouse_qty': warehouse_qty
                })

            # å°‹æ‰¾å€‰åº«ä¸­æœ‰åº«å­˜ä½†å°šæœªéŠ·å”®çš„æ–°ç”¢å“
            new_products = [
                p for p in warehouse_inventory.keys()
                if p not in filtered_sales and warehouse_inventory[p] > 0
            ]
            
            # ç‚ºæ–°ç”¢å“åˆ†é…ç©ºé–“
            if new_products:
                slots_per_new = slots_for_new / len(new_products)
                for p in new_products:
                    warehouse_qty = warehouse_inventory[p]
                    suggested_qty = min(slots_per_new, warehouse_qty)
                    temp_suggestions.append({
                        'productName': p,
                        'suggestedQty_float': suggested_qty,
                        'sales_count': 0,
                        'warehouse_qty': warehouse_qty
                    })
            
            suggestion_list = distribute_remainder(temp_suggestions, available_slots)
            temp_suggestions = [{'productName': p, 'suggestedQty_float': (c / total_sales_volume) * slots_for_existing, 'sales_count': c} for p, c in sales_counts.items()]
            suggestion_list = distribute_remainder(temp_suggestions, slots_for_existing)

        # 4. çµ„åˆæœ€çµ‚çµæœ
        final_suggestion = []
        suggestion_map = {item['productName']: item['suggestedQty'] for item in suggestion_list}
        all_product_names = set(current_inventory.keys()) | set(suggestion_map.keys())

        # æ­£ç¢ºé‚è¼¯ï¼šæœ€å¤§è£œè²¨ç¸½æ•¸é‡æ˜¯è£œè²¨å¾Œçš„ç›®æ¨™åº«å­˜é‡
        warning = None
        total_current = sum(current_inventory.get(name, 0) for name in all_product_names)
        
        # å…ˆå°‡æ‰€æœ‰ç”¢å“çš„å»ºè­°æ•¸é‡è¨­ç‚ºä¸ä½æ–¼ç•¶å‰åº«å­˜
        for name in all_product_names:
            current_qty = current_inventory.get(name, 0)
            suggested_qty = max(current_qty, suggestion_map.get(name, current_qty))
            final_suggestion.append({
                'productName': name,
                'currentQty': current_qty,
                'suggestedQty': suggested_qty,
                'salesCount30d': sales_counts.get(name, 0)
            })

        # æŒ‰ç…§èª¿æ•´é‡ï¼ˆå»ºè­°æ•¸é‡-ç•¶å‰æ•¸é‡ï¼‰æ’åºï¼Œåªä¿ç•™å‰7å€‹éœ€è¦èª¿æ•´çš„é …ç›®
        final_suggestion.sort(key=lambda x: (
            x['suggestedQty'] - x['currentQty'],  # é¦–è¦æ¢ä»¶ï¼šèª¿æ•´é‡
            x['salesCount30d']  # æ¬¡è¦æ¢ä»¶ï¼šéŠ·é‡
        ), reverse=True)

        # åªä¿ç•™éœ€è¦èª¿æ•´çš„å‰7å€‹é …ç›®ï¼Œå…¶ä»–é …ç›®çš„å»ºè­°æ•¸é‡è¨­ç‚ºç•¶å‰åº«å­˜
        needs_adjustment = [x for x in final_suggestion if x['suggestedQty'] - x['currentQty'] > 0]
        no_adjustment = [x for x in final_suggestion if x['suggestedQty'] - x['currentQty'] <= 0]

        if len(needs_adjustment) > 7:
            for item in needs_adjustment[7:]:
                item['suggestedQty'] = item['currentQty']

        final_suggestion = needs_adjustment[:7] + no_adjustment
        final_suggestion.sort(key=lambda x: x['suggestedQty'], reverse=True)

        if total_current >= machine_capacity:
            warning = f"ç¾æœ‰åº«å­˜ç¸½å’Œ({total_current})å·²é”æœ€å¤§è£œè²¨ç¸½æ•¸é‡({machine_capacity})ï¼Œç„¡éœ€è£œè²¨ã€‚"
            for name in all_product_names:
                final_suggestion.append({
                    'productName': name,
                    'currentQty': current_inventory.get(name, 0),
                    'suggestedQty': current_inventory.get(name, 0),
                    'salesCount30d': sales_counts.get(name, 0)
                })
            final_suggestion.sort(key=lambda x: x['suggestedQty'], reverse=True)
            return jsonify({
                "success": True,
                "store_key": store_key,
                "strategy_used": strategy,
                "suggestion": final_suggestion,
                "warning": warning
            })

        # å‰©é¤˜å¯è£œè²¨ç©ºé–“
        available_replenish = machine_capacity - total_current
        # ä¾ç­–ç•¥åˆ†é…é€™äº›ç©ºé–“
        # é‡æ–°è¨ˆç®—åˆ†é…ï¼šæ¯å€‹ç”¢å“çš„è£œè²¨é‡ = åˆ†é…é‡ï¼Œå»ºè­°æ•¸é‡ = ç¾æœ‰åº«å­˜ + åˆ†é…é‡
        # å…ˆä¾ç…§ç­–ç•¥åˆ†é…æ¯”ä¾‹
        # å–å¾—æœ‰éŠ·é‡çš„ç”¢å“åˆ†é…æ¯”ä¾‹
        if strategy == 'stable':
            total_sales_volume = sum(sales_counts.values())
            temp_suggestions = []
            for p, c in sales_counts.items():
                temp_suggestions.append({'productName': p, 'suggestedQty_float': (c / total_sales_volume) * available_replenish, 'sales_count': c})
            distributed = distribute_remainder(temp_suggestions, available_replenish)
        elif strategy == 'aggressive':
            sorted_sales = sorted(sales_counts.items(), key=lambda item: item[1], reverse=True)
            top_3_products = sorted_sales[:3]
            other_products = sorted_sales[3:]
            top_3_sales_volume = sum(c for _, c in top_3_products)
            other_sales_volume = sum(c for _, c in other_products)
            slots_for_top_3 = round(available_replenish * 0.8)
            slots_for_others = available_replenish - slots_for_top_3
            temp_suggestions = []
            if top_3_sales_volume > 0:
                temp_suggestions.extend([{'productName': p, 'suggestedQty_float': (c / top_3_sales_volume) * slots_for_top_3, 'sales_count': c} for p, c in top_3_products])
            if other_sales_volume > 0 and len(other_products) > 0:
                temp_suggestions.extend([{'productName': p, 'suggestedQty_float': (c / other_sales_volume) * slots_for_others, 'sales_count': c} for p, c in other_products])
            distributed = distribute_remainder(temp_suggestions, available_replenish)
        elif strategy == 'exploratory':
            total_sales_volume = sum(sales_counts.values())
            slots_for_existing = round(available_replenish * 0.8)
            temp_suggestions = [{'productName': p, 'suggestedQty_float': (c / total_sales_volume) * slots_for_existing, 'sales_count': c} for p, c in sales_counts.items()]
            distributed = distribute_remainder(temp_suggestions, slots_for_existing)
        else:
            distributed = []

        # å°‡åˆ†é…çµæœè½‰ç‚º dict
        distributed_map = {item['productName']: item['suggestedQty'] for item in distributed}

        # çµ„åˆæœ€çµ‚å»ºè­°ï¼šå»ºè­°æ•¸é‡ = ç¾æœ‰åº«å­˜ + åˆ†é…åˆ°çš„è£œè²¨é‡
        for name in all_product_names:
            current_qty = current_inventory.get(name, 0)
            add_qty = distributed_map.get(name, 0)
            suggested_qty = current_qty + add_qty
            # åªè£œè²¨æ¨¡å¼ä¸‹ï¼Œä¸å»ºè­°æ¸›å°‘ç¾æœ‰åº«å­˜
            if only_add and suggested_qty < current_qty:
                suggested_qty = current_qty
            final_suggestion.append({
                'productName': name,
                'currentQty': current_qty,
                'suggestedQty': suggested_qty,
                'salesCount30d': sales_counts.get(name, 0)
            })
        final_suggestion.sort(key=lambda x: x['suggestedQty'], reverse=True)

        # æœ€çµ‚æª¢æŸ¥ç¸½å’Œï¼Œç†è«–ä¸Šä¸æœƒè¶…é machine_capacity
        total_final = sum(item['suggestedQty'] for item in final_suggestion)
        if total_final > machine_capacity:
            warning = f"åˆ†é…å¾Œç¸½åº«å­˜({total_final})è¶…éæœ€å¤§è£œè²¨ç¸½æ•¸é‡({machine_capacity})ï¼Œå·²è‡ªå‹•èª¿æ•´è‡³ä¸Šé™ã€‚"
            # ä¾ç¾æœ‰åº«å­˜æ’åºï¼Œä¾åºæ¸›å°‘è‡³ç¬¦åˆä¸Šé™
            over = total_final - machine_capacity
            for item in sorted(final_suggestion, key=lambda x: x['suggestedQty'], reverse=True):
                if over <= 0:
                    break
                reducible = item['suggestedQty'] - item['currentQty']
                if reducible > 0:
                    reduce_by = min(reducible, over)
                    item['suggestedQty'] -= reduce_by
                    over -= reduce_by
            # å†æ¬¡æ’åº
            final_suggestion.sort(key=lambda x: x['suggestedQty'], reverse=True)

        return jsonify({
            "success": True,
            "store_key": store_key,
            "strategy_used": strategy,
            "suggestion": final_suggestion,
            "warning": warning
        })

    except Exception as e:
        db.rollback()
        logging.error(f"Error in replenishment suggestion for {store_key}: {e}", exc_info=True)
        return jsonify({"success": False, "message": str(e)}), 500
    finally:
        db.close()

# --- Password Protected Routes ---
@app.route('/login', methods=['GET', 'POST'])
def login():
    """Handles the login process."""
    if request.method == 'POST':
        password = request.form.get('password')
        # Load the access password from environment variables
        access_password = os.getenv("ACCESS_PASSWORD")
        
        if not access_password:
             flash("éŒ¯èª¤ï¼šæ‡‰ç”¨ç¨‹å¼æœªè¨­å®šè¨ªå•å¯†ç¢¼ã€‚")
             return render_template('login.html'), 500

        if password == access_password:
            session['logged_in'] = True
            return redirect('/')
        else:
            flash('å¯†ç¢¼éŒ¯èª¤ï¼Œè«‹é‡è©¦ã€‚')
            return redirect('/login')
            
    return render_template('login.html')

@app.route('/logout')
def logout():
    """Logs the user out."""
    session.pop('logged_in', None)
    return redirect('/login')


# --- Static File Serving ---
@app.route('/')
def serve_index():
    if not session.get('logged_in'):
        return redirect('/login')
    return send_from_directory(script_dir, 'index.html')

@app.route('/presentation')
def serve_presentation():
    return send_from_directory(script_dir, 'presentation.html')


@app.route('/presentation_sample')
def serve_presentation_sample():
    # Legacy route: redirect to the canonical sample path
    return redirect('/sample')


@app.route('/sample')
def serve_sample():
    # Canonical sample URL (no .html)
    return send_from_directory(script_dir, 'presentation_sample.html')

@app.route('/<path:path>')
def serve_static_files(path):
    # This will serve other files like script.js
    # Allow presentation_sample.html to be requested directly but prefer clean URL
    if path == 'presentation.html':
        return redirect('/presentation')
    if path == 'presentation_sample.html':
        return redirect('/sample')
    return send_from_directory(script_dir, path)


# --- Scheduler Setup ---
def run_scheduler():
    """
    Sets up and runs the scheduler in a loop.
    """
    # Schedule the inventory scraper to run at 1 minute past the hour.
    schedule.every().hour.at(":01").do(run_inventory_scraper_background)
    logging.info("Scheduler started for inventory: will run every hour at 1 minute past.")

    # Schedule the sales scraper to run daily at 23:55 Taiwan Time (UTC+8), which is 15:55 UTC.
    schedule.every().day.at("15:55").do(run_sales_scraper_background)
    logging.info("Scheduler started for sales: will run daily at 15:55 UTC (23:55 Taiwan Time).")
    
    # Schedule the warehouse scraper to run daily at 23:50 Taiwan Time (UTC+8), which is 15:50 UTC.
    schedule.every().day.at("15:50").do(run_warehouse_scraper_background)
    logging.info("Scheduler started for warehouse: will run daily at 15:50 UTC (23:50 Taiwan Time).")
    
    # Run the scheduler loop
    while True:
        schedule.run_pending()
        time.sleep(1)


@app.route('/debug/db-stats')
def debug_db_stats():
    """Temporary diagnostic endpoint: returns counts of key tables and DB config."""
    # WARNING: This endpoint may expose counts of rows; keep it temporary and remove after debugging.
    db: Session = next(get_db())
    try:
        inv_count = db.query(Inventory).count()
        wh_count = db.query(Warehouse).count()
        store_count = db.query(Store).count()
        return jsonify({
            "success": True,
            "inventory_count": inv_count,
            "warehouse_count": wh_count,
            "store_count": store_count,
            "uses_external_database": bool(os.getenv('DATABASE_URL'))
        })
    except Exception as e:
        logging.exception('Error while gathering DB stats')
        return jsonify({"success": False, "error": str(e)}), 500
    finally:
        db.close()

# --- Endpoints for Manual Testing ---
@app.route('/test-run-warehouse-scraper', methods=['GET'])
def test_run_warehouse_scraper():
    """ç”¨æ–¼æ‰‹å‹•è§¸ç™¼å€‰åº«çˆ¬èŸ²çš„æ¸¬è©¦ç«¯é»ã€‚"""
    logging.info("æ”¶åˆ°æ‰‹å‹•è§¸ç™¼å€‰åº«çˆ¬èŸ²çš„è«‹æ±‚ã€‚")
    thread = threading.Thread(target=run_warehouse_scraper_background)
    thread.start()
    return "å€‰åº«çˆ¬èŸ²å·¥ä½œå·²æ‰‹å‹•è§¸ç™¼é€²è¡Œæ¸¬è©¦ã€‚"

@app.route('/test-run-inventory-scraper', methods=['GET'])
def test_run_inventory_scraper():
    """A simple endpoint to manually trigger the inventory scraper for testing."""
    logging.info("Manual trigger for inventory scraper received.")
    thread = threading.Thread(target=run_inventory_scraper_background)
    thread.start()
    return "Inventory scraper job manually triggered for testing."

@app.route('/test-run-sales-scraper', methods=['GET'])
def test_run_sales_scraper():
    """A simple endpoint to manually trigger the sales scraper for testing."""
    logging.info("Manual trigger for sales scraper received.")
    thread = threading.Thread(target=run_sales_scraper_background)
    thread.start()
    return "Sales scraper job manually triggered for testing."


# --- è£œè²¨å–®ç”Ÿæˆç›¸é—œåŠŸèƒ½ ---
@app.route('/api/generate-replenishment-form', methods=['POST'])
def generate_replenishment_form():
    """æ ¹æ“šè£œè²¨å»ºè­°ç”Ÿæˆè£œè²¨å–®Excel"""
    try:
        # ç²å–è«‹æ±‚æ•¸æ“š
        data = request.get_json()
        if not data or 'suggestions' not in data:
            return jsonify({'success': False, 'message': 'ç„¡æ•ˆçš„è«‹æ±‚æ•¸æ“š'}), 400
        
        suggestions = data['suggestions']
        if not suggestions:
            return jsonify({'success': False, 'message': 'æ²’æœ‰è£œè²¨å»ºè­°æ•¸æ“š'}), 400

        # åŠ è¼‰æ¨¡æ¿
        template_path = os.path.join(script_dir, 'è£œè²¨å–®.xlsx')
        current_date = datetime.now().strftime('%Y%m%d')
        output_path = os.path.join(script_dir, f'{current_date}-åœ¨é‚£è£¡-æ¯æ—¥å•†å“è£œè²¨æ˜ç´°è¡¨.xlsx')
        
        if not os.path.exists(template_path):
            return jsonify({'success': False, 'message': 'æ‰¾ä¸åˆ°è£œè²¨å–®æ¨¡æ¿'}), 404
            
        # è¤‡è£½æ¨¡æ¿
        shutil.copy2(template_path, output_path)
        
        # æ‰“é–‹å·¥ä½œç°¿
        wb = load_workbook(output_path)
        ws = wb.active
        
        # å¡«å¯«åŸºæœ¬ä¿¡æ¯
        ws['F1'] = datetime.now().strftime('%Y/%m/%d')  # è£œè²¨æ—¥æœŸ
        ws['H2'] = len(suggestions)  # å¢åŠ é»ä½æ•¸
        
        # æ©Ÿå°ä½ç½®æ˜ å°„
        machine_positions = [
            {'name': 'A4', 'items': ('B4', 'D4', 'B12', 'D12'), 'item_range': (4, 11)},  # ç¬¬ä¸€å°
            {'name': 'E4', 'items': ('F4', 'H4', 'F12', 'H12'), 'item_range': (4, 11)},  # ç¬¬äºŒå°
            {'name': 'A17', 'items': ('B17', 'D17', 'B25', 'D25'), 'item_range': (17, 24)},  # ç¬¬ä¸‰å°
            {'name': 'E17', 'items': ('F17', 'H17', 'F25', 'H25'), 'item_range': (17, 24)},  # ç¬¬å››å°
            {'name': 'A30', 'items': ('B30', 'D30', 'B38', 'D38'), 'item_range': (30, 37)},  # ç¬¬äº”å°
            {'name': 'E30', 'items': ('F30', 'H30', 'F38', 'H38'), 'item_range': (30, 37)},  # ç¬¬å…­å°
            {'name': 'A43', 'items': ('B43', 'D43', 'B51', 'D51'), 'item_range': (43, 50)},  # ç¬¬ä¸ƒå°
            {'name': 'E43', 'items': ('F43', 'H43', 'E51', 'H51'), 'item_range': (43, 50)}   # ç¬¬å…«å°
        ]

        # å¡«å¯«æ¯å°æ©Ÿå™¨çš„æ•¸æ“š
        for i, suggestion in enumerate(suggestions[:8]):  # æœ€å¤šè™•ç†8å°æ©Ÿå™¨
            pos = machine_positions[i]
            ws[pos['name']] = suggestion['machine']  # å¡«å¯«æ©Ÿå°åç¨±
            
            # ç²å–éœ€è¦å¢åŠ åº«å­˜çš„ç”¢å“ï¼ˆåªå–æ­£æ•¸èª¿æ•´ï¼‰
            adjusted_items = [item for item in suggestion['suggestion'] 
                            if item['suggestedQty'] - item['currentQty'] > 0]
            
            # æŒ‰èª¿æ•´æ•¸é‡æ’åºä¸¦åªå–å‰7å€‹
            adjusted_items.sort(key=lambda x: x['suggestedQty'] - x['currentQty'], reverse=True)
            adjusted_items = adjusted_items[:7]  # é™åˆ¶æ¯å°æœ€å¤š7å€‹èª¿æ•´é …ç›®
            
            # å¡«å¯«ç”¢å“ä¿¡æ¯
            for j, item in enumerate(adjusted_items):
                row = pos['item_range'][0] + j
                item_col = pos['items'][0][0]  # Bæˆ–F
                qty_col = pos['items'][1][0]   # Dæˆ–H
                
                # å¡«å¯«ç”¢å“åç¨±å’Œèª¿æ•´æ•¸é‡
                ws[f'{item_col}{row}'] = item['productName']
                ws[f'{qty_col}{row}'] = item['suggestedQty'] - item['currentQty']
            
            # å¡«å¯«åº«å­˜å’Œç¸½æ•¸
            current_stock = sum(item['currentQty'] for item in suggestion['suggestion'])
            total_adjustment = sum(item['suggestedQty'] - item['currentQty'] 
                                 for item in suggestion['suggestion'])
            
            # ä½¿ç”¨machine_positionsä¸­å®šç¾©çš„å–®å…ƒæ ¼ä½ç½®
            ws[pos['items'][2]] = current_stock  # æ©Ÿå…§åº«å­˜
            ws[pos['items'][3]] = total_adjustment  # è£œè²¨ç¸½æ•¸

        # ä¿å­˜å·¥ä½œç°¿
        wb.save(output_path)
        
        # è¿”å›æ–‡ä»¶åä¾›ä¸‹è¼‰
        filename = os.path.basename(output_path)
        return jsonify({
            'success': True, 
            'message': 'è£œè²¨å–®ç”ŸæˆæˆåŠŸ',
            'filename': filename
        })
        
    except Exception as e:
        logging.error(f"ç”Ÿæˆè£œè²¨å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return jsonify({'success': False, 'message': f'ç”Ÿæˆè£œè²¨å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}'}), 500

@app.route('/download-replenishment-form/<filename>')
def download_replenishment_form(filename):
    """ä¸‹è¼‰ç”Ÿæˆçš„è£œè²¨å–®"""
    try:
        return send_from_directory(script_dir, filename, as_attachment=True)
    except Exception as e:
        return jsonify({'success': False, 'message': str(e)}), 404

# --- éŠ·å”®æ˜ç´°è¡¨ç”Ÿæˆç›¸é—œåŠŸèƒ½ ---
@app.route('/api/generate-sales-detail', methods=['POST'])
def generate_sales_detail():
    """æ ¹æ“šæ—¥æœŸç¯„åœç”ŸæˆéŠ·å”®æ˜ç´°è¡¨Excel"""
    try:
        data = request.get_json()
        if not data or 'startDate' not in data or 'endDate' not in data:
            return jsonify({'success': False, 'message': 'ç„¡æ•ˆçš„è«‹æ±‚æ•¸æ“š'}), 400

        start_date = datetime.fromisoformat(data['startDate'])
        end_date = datetime.fromisoformat(data['endDate'])

        # å¯é¸çš„åˆ†åº—/ç”¢å“éæ¿¾æ¢ä»¶ï¼ˆä¾†è‡ªå‰ç«¯å¤šé¸ï¼‰
        selected_stores = data.get('stores') or []
        selected_products = data.get('products') or []

        logging.info(f"Received generate-sales-detail request with stores={selected_stores} products={selected_products}")

        db: Session = next(get_db())
        try:
            # è¨­å®šæ—¥æœŸç¯„åœçš„çµæŸæ™‚é–“ç‚ºç•¶å¤©çš„æœ€å¾Œä¸€åˆ»
            end_date = end_date.replace(hour=23, minute=59, second=59, microsecond=999999)
            
            # ç²å–æŒ‡å®šæ—¥æœŸç¯„åœå…§çš„æ‰€æœ‰äº¤æ˜“
            transactions_query = db.query(Transaction).filter(
                Transaction.transaction_time >= start_date,
                Transaction.transaction_time <= end_date
            )

            # å¦‚æœå‰ç«¯æœ‰æä¾›åˆ†åº—éæ¿¾ï¼Œå°‡ store_key çš„åº—åéƒ¨åˆ†æ¯”å°
            if selected_stores:
                # store_key æ ¼å¼ç‚º 'StoreName-machineId'ï¼Œå› æ­¤æ¯”å°ä»¥ store_key.startswith(storeName)
                store_filters = [Transaction.store_key.startswith(s) for s in selected_stores]
                # SQLAlchemy ä¸èƒ½ç›´æ¥ä½¿ç”¨ python list of expressions like this; ä½¿ç”¨ OR çµ„åˆ
                from sqlalchemy import or_
                or_conditions = [Transaction.store_key.startswith(s) for s in selected_stores]
                transactions_query = transactions_query.filter(or_(*or_conditions))

            # å¦‚æœå‰ç«¯æœ‰æä¾›ç”¢å“éæ¿¾
            if selected_products:
                from sqlalchemy import or_
                prod_conditions = [Transaction.product_name == p for p in selected_products]
                transactions_query = transactions_query.filter(or_(*prod_conditions))

            transactions = transactions_query.order_by(Transaction.store_key, Transaction.product_name).all()

            if not transactions:
                return jsonify({'success': False, 'message': 'æŒ‡å®šæ—¥æœŸç¯„åœå…§æ²’æœ‰äº¤æ˜“è¨˜éŒ„'}), 404
                
            # è¨˜éŒ„æŸ¥è©¢åˆ°çš„äº¤æ˜“è¨˜éŒ„ç¯„åœ
            logging.info(f"Query date range: from {start_date} to {end_date}")
            logging.info(f"Found {len(transactions)} transactions after applying filters (stores/products)")

            # å»ºç«‹ Excel å·¥ä½œç°¿
            wb = Workbook()
            ws = wb.active
            ws.title = "éŠ·å”®æ˜ç´°"

            # è¨­ç½®æ¨™é¡Œè¡Œ
            ws['A1'] = 'å•†å“'
            ws['B1'] = 'å–®åƒ¹'
            ws['C1'] = 'ä»½æ•¸'
            ws['D1'] = 'å°è¨ˆ'

            # çµ±è¨ˆæ•¸æ“š
            sales_summary = {}
            total_amount = 0  # ç”¨æ–¼é©—è­‰ç¸½é‡‘é¡
            transaction_count = 0  # ç”¨æ–¼é©—è­‰äº¤æ˜“ç­†æ•¸
            
            # ç¬¬ä¸€æ¬¡éæ­·ï¼šæ‰¾å‡ºæ¯å€‹ç”¢å“çš„æœ€æ–°å–®åƒ¹ï¼ˆç”¨æ–¼å–®åƒ¹å›å¾©ï¼‰ï¼Œ
            # ä½†æˆ‘å€‘å…è¨±åŒä¸€ç”¢å“å­˜åœ¨å¤šå€‹ä¸åŒçš„å·²é‚„åŸå–®åƒ¹ï¼Œ
            # å› æ­¤æ­¤éšæ®µåªè² è²¬è¨ˆç®—å–®ç­†äº¤æ˜“çš„é‚„åŸå–®åƒ¹ã€‚
            def normalized_unit_price(amount):
                try:
                    price = int(round(amount))
                except Exception:
                    price = int(amount)
                last_digit = price % 10
                if last_digit in (1, 2):
                    return price - 2
                return price
            
            # ç¬¬äºŒæ¬¡éæ­·ï¼šè¨ˆç®—æ¯å€‹åº—å®¶çš„æ¯å€‹ç”¢å“åœ¨ä¸åŒï¼ˆé‚„åŸå¾Œï¼‰å–®åƒ¹ä¸‹çš„æ•¸é‡èˆ‡ç‡Ÿæ”¶
            # çµæ§‹ï¼šsales_summary[store][product][price] -> {'count': n, 'total': x}
            sales_summary = {}
            for t in transactions:
                transaction_count += 1
                store_name = t.store_key.split('-')[0]
                product_name = t.product_name or 'UNKNOWN'

                # æ¯ç­†äº¤æ˜“é‡‘é¡ = å¯¦éš›äº¤æ˜“é‡‘é¡
                transaction_amount = t.amount or 0
                total_amount += transaction_amount

                # ä»¥é‚„åŸå¾Œçš„å–®åƒ¹ä½œç‚º group key
                unit_price = normalized_unit_price(t.amount)

                store_map = sales_summary.setdefault(store_name, {})
                product_map = store_map.setdefault(product_name, {})
                price_entry = product_map.setdefault(unit_price, {'count': 0, 'total': 0})
                price_entry['count'] += 1
                price_entry['total'] += transaction_amount
            
            # è©³ç´°çš„æ—¥èªŒè¨˜éŒ„
            logging.info(f"Total transactions: {transaction_count}")
            logging.info(f"Total amount: {total_amount}")

            # è¨ˆç®—å”¯ä¸€çš„ product-price çµ„åˆæ•¸èˆ‡é©—è­‰ç¸½é‡‘é¡
            unique_price_combinations = 0
            summary_total = 0
            for store_name, products in sales_summary.items():
                for product_name, price_map in products.items():
                    for price, rec in price_map.items():
                        unique_price_combinations += 1
                        summary_total += rec.get('total', 0)

            logging.info(f"Unique product-price combinations: {unique_price_combinations}")
            if summary_total != total_amount:
                logging.error(f"Amount mismatch! Summary: {summary_total}, Transactions: {total_amount}")

            # æŒ‰åº—é‹ªåŒ¯ç¸½çµ±è¨ˆä»¥ä¾›æ—¥èªŒé¡¯ç¤º
            store_totals = {}
            for store_name, products in sales_summary.items():
                store_totals.setdefault(store_name, {'total': 0, 'transactions': 0})
                for product_name, price_map in products.items():
                    for price, rec in price_map.items():
                        store_totals[store_name]['total'] += rec.get('total', 0)
                        store_totals[store_name]['transactions'] += rec.get('count', 0)
            
            for store, stats in store_totals.items():
                logging.info(f"Store: {store}")
                logging.info(f"  - Total amount: {stats['total']}")
                logging.info(f"  - Transaction count: {stats['transactions']}")
                logging.info(f"  - Average transaction: {stats['total'] / stats['transactions']:.2f}")

            # æŒ‰åº—å®¶åˆ†çµ„ä¸¦æ”¯æ´æ¯å€‹ç”¢å“å¤šå€‹åƒ¹æ ¼ï¼ˆä»¥é‚„åŸå¾Œçš„å–®åƒ¹ç‚ºéµï¼‰
            # sales_summary ç¾åœ¨ä»¥ store->product->price èšåˆ
            store_groups = {}
            for store_name in sorted(sales_summary.keys()):
                store_entry = {'sales': [], 'total_count': 0, 'total_amount': 0}
                for product_name in sorted(sales_summary[store_name].keys()):
                    price_map = sales_summary[store_name][product_name]
                    # å°‡ä¸åŒåƒ¹æ ¼æŒ‰åƒ¹æ ¼é«˜åˆ°ä½æ’åº
                    price_rows = []
                    for price in sorted(price_map.keys(), reverse=True):
                        rec = price_map[price]
                        price_rows.append({'price': price, 'count': rec['count'], 'total': rec['total']})
                        store_entry['total_count'] += rec['count']
                        store_entry['total_amount'] += rec['total']

                    store_entry['sales'].append({'product': product_name, 'prices': price_rows})

                # æ ¹æ“šåº—å…§ç¸½æ”¶å…¥æ’åºç”¢å“ï¼ˆä¸»è¦é¡¯ç¤ºé †åºï¼‰
                store_entry['sales'].sort(key=lambda p: sum(r['total'] for r in p['prices']), reverse=True)
                store_groups[store_name] = store_entry

            # è¨­ç½®æ¨£å¼
            from openpyxl.styles import Font, PatternFill, Border, Side, Alignment
            
            # å­—é«”æ¨£å¼
            header_font = Font(bold=True, size=11, name='å¾®è»Ÿæ­£é»‘é«”')
            normal_font = Font(size=10, name='å¾®è»Ÿæ­£é»‘é«”')
            store_font = Font(bold=True, size=11, name='å¾®è»Ÿæ­£é»‘é«”')  # èª¿æ•´ç‚ºèˆ‡æ¨™é¡Œç›¸åŒå¤§å°
            
            # å¡«å……é¡è‰²
            header_fill = PatternFill(start_color='2F75B5', end_color='2F75B5', fill_type='solid')  # ä¸»é¡Œè—
            subtotal_fill = PatternFill(start_color='BDD7EE', end_color='BDD7EE', fill_type='solid')  # æ·ºè—è‰²
            total_fill = PatternFill(start_color='8EA9DB', end_color='8EA9DB', fill_type='solid')    # ä¸­è—è‰²
            alternate_fill = PatternFill(start_color='F5F5F5', end_color='F5F5F5', fill_type='solid') # æ·ºç°è‰²
            
            # é‚Šæ¡†æ¨£å¼
            thin_border = Border(
                left=Side(style='thin', color='BFBFBF'),
                right=Side(style='thin', color='BFBFBF'),
                top=Side(style='thin', color='BFBFBF'),
                bottom=Side(style='thin', color='BFBFBF')
            )
            
            # ç‰¹æ®Šé‚Šæ¡†æ¨£å¼ï¼ˆç”¨æ–¼æ¨™é¡Œå’Œå°è¨ˆè¡Œï¼‰
            bottom_border = Border(
                left=Side(style='thin', color='BFBFBF'),
                right=Side(style='thin', color='BFBFBF'),
                top=Side(style='thin', color='BFBFBF'),
                bottom=Side(style='medium', color='2F75B5')  # åº•éƒ¨ä½¿ç”¨è¼ƒç²—çš„è—è‰²é‚Šæ¡†
            )
            
            # å°é½Šæ–¹å¼
            center_alignment = Alignment(horizontal='center', vertical='center')
            right_alignment = Alignment(horizontal='right', vertical='center')
            
            # è¨­ç½®æ¨™é¡Œæ¨£å¼
            headers = ['å•†å“', 'å–®åƒ¹', 'ä»½æ•¸', 'å°è¨ˆ']  # ç§»é™¤åº—é‹ªæ¬„ä½
            for col, header in zip(['A1', 'B1', 'C1', 'D1'], headers):
                cell = ws[col]
                cell.value = header
                cell.font = Font(bold=True, size=11, name='å¾®è»Ÿæ­£é»‘é«”', color='FFFFFF')
                cell.fill = header_fill
                cell.border = bottom_border
                cell.alignment = center_alignment

            # å¡«å…¥æ•¸æ“šï¼ŒåŒ…æ‹¬æ¯å€‹åº—å®¶çš„å°è¨ˆ
            current_row = 2
            grand_total_count = 0
            grand_total_amount = 0

            for store, data in store_groups.items():
                # åº—å®¶åç¨±è¡Œ
                ws.merge_cells(f'A{current_row}:D{current_row}')
                ws[f'A{current_row}'] = store
                ws[f'A{current_row}'].font = store_font
                ws[f'A{current_row}'].fill = subtotal_fill
                ws[f'A{current_row}'].alignment = Alignment(horizontal='left', vertical='center')
                for col in ['A', 'B', 'C', 'D']:
                    ws[f'{col}{current_row}'].border = thin_border
                
                last_header_row = current_row  # è¨˜éŒ„åº—å®¶æ¨™é¡Œè¡Œçš„ä½ç½®
                current_row += 1

                # å¡«å…¥è©²åº—å®¶çš„æ‰€æœ‰å•†å“æ•¸æ“šï¼ˆæ”¯æ´åŒå•†å“å¤šåƒ¹æ ¼ï¼‰
                # ä½¿ç”¨ product_block_idx ä¾†å°æ•´å€‹å•†å“å€å¡Šé€²è¡Œäº¤æ›¿åº•è‰²ï¼Œ
                # ä»¥é¿å…å› ç‚ºåŒå•†å“å¤šåƒ¹æ ¼é€ æˆçš„åˆ—æ•¸å·®ç•°è€Œå°è‡´è¦–è¦ºä¸Šè·¨åº—å®¶éŒ¯ä½ã€‚
                product_block_idx = 0
                for sale in data['sales']:
                    product_name = sale['product']
                    price_rows = sale.get('prices', [])
                    if not price_rows:
                        # è‹¥æ²’æœ‰åƒ¹æ ¼è³‡æ–™ï¼Œè·³éï¼ˆä¸”ä¸è¨ˆå…¥äº¤æ›¿åºåˆ—ï¼‰
                        continue

                    # æ±ºå®šè©²å•†å“å€å¡Šæ˜¯å¦éœ€è¦å¡«å……èƒŒæ™¯ï¼ˆä¿æŒæ•´å€‹å•†å“å€å¡ŠåŒè‰²ï¼‰
                    should_fill_block = (product_block_idx % 2 == 1)

                    start_row_for_product = current_row
                    # ç‚ºæ¯å€‹åƒ¹æ ¼åˆ—å¯«å…¥ä¸€è¡Œ
                    for pr in price_rows:
                        ws[f'B{current_row}'] = pr['price']
                        ws[f'C{current_row}'] = pr['count']
                        ws[f'D{current_row}'] = pr['total']

                        # è¨­å®šæ¨£å¼
                        for col, value in [(f'B{current_row}', pr['price']), (f'C{current_row}', pr['count']), (f'D{current_row}', pr['total'])]:
                            ws[col].font = normal_font
                            ws[col].border = thin_border
                            ws[col].alignment = Alignment(horizontal='right', vertical='center')
                            if col.startswith('B'):
                                ws[col].number_format = '#,##0'
                            else:
                                ws[col].number_format = '#,##0'

                        # å¦‚æœè©²å•†å“å€å¡Šéœ€è¦å¡«è‰²ï¼Œå°æ•´è¡Œæ‰€æœ‰åˆ—å¡«å……
                        if should_fill_block:
                            for col in ['A', 'B', 'C', 'D']:
                                ws[f'{col}{current_row}'].fill = PatternFill(start_color='F5F5F5', end_color='F5F5F5', fill_type='solid')

                        current_row += 1

                    end_row_for_product = current_row - 1
                    # åˆä½µ A æ¬„ç‚ºç”¢å“åç¨±ä»¥æé«˜å¯è®€æ€§ï¼ˆæ•´å€‹å•†å“å€å¡Šä¸å¦åŠ ç©ºè¡Œï¼‰
                    ws.merge_cells(start_row=start_row_for_product, start_column=1, end_row=end_row_for_product, end_column=1)
                    ws[f'A{start_row_for_product}'] = product_name
                    ws[f'A{start_row_for_product}'].font = normal_font
                    ws[f'A{start_row_for_product}'].alignment = Alignment(horizontal='left', vertical='center')

                    # å•†å“å€å¡Šè™•ç†å®Œç•¢ï¼Œç§»å‹•åˆ°ä¸‹ä¸€å€‹å•†å“å¡Š
                    product_block_idx += 1

                # æ·»åŠ è©²åº—å®¶çš„å°è¨ˆ
                ws[f'A{current_row}'] = f"{store} å°è¨ˆ"
                ws[f'C{current_row}'] = data['total_count']
                ws[f'D{current_row}'] = data['total_amount']
                
                # è¨­ç½®å°è¨ˆè¡Œçš„æ¨£å¼
                for col in ['A', 'B', 'C', 'D']:
                    ws[f'{col}{current_row}'].fill = subtotal_fill
                    ws[f'{col}{current_row}'].font = header_font
                    ws[f'{col}{current_row}'].border = thin_border
                    ws[f'{col}{current_row}'].alignment = right_alignment
                
                # ç‚ºå°è¨ˆçš„æ•¸å­—è¨­ç½®æ ¼å¼
                ws[f'C{current_row}'].number_format = '#,##0'  # ç¸½ä»½æ•¸ä½¿ç”¨åƒåˆ†ä½
                ws[f'D{current_row}'].number_format = '#,##0'  # ç¸½é‡‘é¡ä½¿ç”¨åƒåˆ†ä½
                ws[f'A{current_row}'].alignment = Alignment(horizontal='left', vertical='center')

                current_row += 2  # æ·»åŠ ä¸€å€‹ç©ºè¡Œ

                # ç´¯åŠ åˆ°ç¸½è¨ˆ
                grand_total_count += data['total_count']
                grand_total_amount += data['total_amount']

            current_row -= 1  # ç§»é™¤æœ€å¾Œä¸€å€‹å¤šé¤˜çš„ç©ºè¡Œ

            # æ·»åŠ ç¸½è¨ˆè¡Œ
            ws[f'A{current_row}'] = "ç¸½è¨ˆ"
            ws[f'C{current_row}'] = grand_total_count
            ws[f'D{current_row}'] = grand_total_amount

            # è¨­ç½®ç¸½è¨ˆè¡Œçš„æ¨£å¼
            for col in ['A', 'B', 'C', 'D']:
                ws[f'{col}{current_row}'].fill = total_fill
                ws[f'{col}{current_row}'].font = header_font
                ws[f'{col}{current_row}'].border = thin_border
                ws[f'{col}{current_row}'].alignment = right_alignment
            
            # ç‚ºç¸½è¨ˆçš„æ•¸å­—è¨­ç½®æ ¼å¼
            ws[f'C{current_row}'].number_format = '#,##0'  # ç¸½ä»½æ•¸ä½¿ç”¨åƒåˆ†ä½
            ws[f'D{current_row}'].number_format = '#,##0'  # ç¸½é‡‘é¡ä½¿ç”¨åƒåˆ†ä½
            ws[f'A{current_row}'].alignment = Alignment(horizontal='left', vertical='center')

            # è¨­ç½®æ¬„å¯¬
            ws.column_dimensions['A'].width = 45  # å•†å“åç¨±ï¼ˆå¢åŠ å¯¬åº¦ï¼‰
            ws.column_dimensions['B'].width = 15  # å–®åƒ¹
            ws.column_dimensions['C'].width = 12  # ä»½æ•¸
            ws.column_dimensions['D'].width = 18  # å°è¨ˆ

            # è¨­ç½®åˆ—é«˜
            ws.row_dimensions[1].height = 25  # æ¨™é¡Œåˆ—åŠ é«˜
            
            # è¨­ç½®å·¥ä½œè¡¨å…¶ä»–å±¬æ€§
            ws.freeze_panes = 'A2'  # å‡çµé¦–è¡Œ
            ws.sheet_view.showGridLines = False  # éš±è—ç¶²æ ¼ç·š

            # ç”Ÿæˆæ—¥æœŸç¯„åœå­—ä¸²
            start_str = start_date.strftime('%Y%m%d')
            end_str = end_date.strftime('%Y%m%d')
            filename = f'sales_detail_{start_str}-{end_str}.xlsx'
            output_path = os.path.join(script_dir, filename)
            wb.save(output_path)

            return jsonify({
                'success': True,
                'message': 'æ˜ç´°è¡¨ç”ŸæˆæˆåŠŸ',
                'filename': filename
            })

        except Exception as e:
            logging.error(f"ç”Ÿæˆæ˜ç´°è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}", exc_info=True)
            return jsonify({'success': False, 'message': f'ç”Ÿæˆæ˜ç´°è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}'}), 500
        finally:
            db.close()

    except Exception as e:
        return jsonify({'success': False, 'message': str(e)}), 400

@app.route('/download-sales-detail/<filename>')
def download_sales_detail(filename):
    """ä¸‹è¼‰ç”Ÿæˆçš„éŠ·å”®æ˜ç´°è¡¨"""
    try:
        return send_from_directory(script_dir, filename, as_attachment=True)
    except Exception as e:
        return jsonify({'success': False, 'message': str(e)}), 404

# --- Main Execution ---
if __name__ == '__main__':
    # This block is for local development testing only.
    # When deployed on Render with Gunicorn, this block will not be executed.
    # The scheduler thread is started below in the global scope.
    logging.info("Starting Flask development server for local testing...")
    app.run(host='0.0.0.0', port=5001, debug=False)

# --- Start the scheduler thread when the application module is loaded ---
# This ensures it runs even when started by Gunicorn on Render.
logging.info("Starting the background scheduler thread...")
scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)
scheduler_thread.start()
logging.info("Background scheduler thread has been started.") 